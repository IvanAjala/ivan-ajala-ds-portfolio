# ğŸ“Š Notebook 04 - Modelagem Preditiva

![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white) ![Pandas](https://img.shields.io/badge/Pandas-2.0+-150458?style=for-the-badge&logo=pandas&logoColor=white) ![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-1.3+-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white) ![Keras](https://img.shields.io/badge/Keras-2.10+-D00000?style=for-the-badge&logo=keras&logoColor=white) ![Stable-Baselines3](https://img.shields.io/badge/Stable--Baselines3-2.0+-4285F4?style=for-the-badge&logo=tensorflow&logoColor=white) ![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-F37626?style=for-the-badge&logo=jupyter&logoColor=white) ![Status](https://img.shields.io/badge/Status-âœ…%20ConcluÃ­do-success?style=for-the-badge) ![CÃ©lulas](https://img.shields.io/badge/CÃ©lulas-136-yellow?style=for-the-badge)  ![Complexidade](https://img.shields.io/badge/Complexidade-â­â­â­â­â­-orange?style=for-the-badge) 

**Sistema Inteligente de RetenÃ§Ã£o de Clientes - TelecomunicaÃ§Ãµes** 

[ğŸ““ Notebook](./04_modelagem_preditiva.ipynb) â€¢ [ğŸ“Š Dataset](../data/processed/) â€¢ [ğŸ“š Docs](../docs/) 

--- 
## ğŸ“‹ VisÃ£o Geral 

| ğŸ“Š MÃ©trica              | ğŸ“ˆ Valor                       |
| ----------------------- | ------------------------------ |
| **Arquivo**             | `04_modelagem_preditiva.ipynb` |
| **Tipo**                | ğŸ“ˆ Modelagem Preditiva         |
| **Total de CÃ©lulas**    | 136                            |
| **CÃ©lulas de CÃ³digo**   | 71 (52.2%)                     |
| **CÃ©lulas de Markdown** | 65 (47.8%)                     |
| **Complexidade**        | â­â­â­â­â­ (AvanÃ§ado)               |
| **Tempo Estimado**      | 90+ minutos                    |
| **Data de CriaÃ§Ã£o**     | 06/02/2026                     |
| **Ãšltima AtualizaÃ§Ã£o**  | 18/02/2026                     |

--- 
## ğŸ¯ Objetivo Principal 

Este notebook tem como objetivo principal **treinar, comparar e selecionar o melhor modelo preditivo de churn**, com foco em: 

- âœ… **Maximizar o Recall:** Para identificar o maior nÃºmero possÃ­vel de clientes em risco de churn. 
- âœ… **Garantir a Interpretabilidade:** Para entender os fatores de churn e criar estratÃ©gias de retenÃ§Ã£o acionÃ¡veis. 
- âœ… **Calibrar Probabilidades:** Para obter previsÃµes de risco confiÃ¡veis, essenciais para segmentar clientes "neutros". 
- âœ… **Validar Estatisticamente:** Para assegurar a robustez e generalizaÃ§Ã£o dos modelos. 
- âœ… **Analisar Trade-offs de NegÃ³cio:** Para justificar a escolha do modelo com base em impacto financeiro e operacional. 

--- 
## ğŸš€ Resultados AlcanÃ§ados 

### ğŸ“Š EstatÃ­sticas Finais do Modelo Selecionado 

| ğŸ“ˆ MÃ©trica             | ğŸ“Š Valor                           | ğŸ¯ Impacto                            |
| ---------------------- | ---------------------------------- | ------------------------------------- |
| **Modelo Selecionado** | RegressÃ£o LogÃ­stica Calibrada (CV) | Melhor trade-off                      |
| **ROC-AUC**            | 0.8404                             | Boa capacidade de discriminaÃ§Ã£o       |
| **Recall**             | 0.7193                             | Identifica ~72% dos clientes em churn |
| **Brier Score**        | 0.1563                             | Probabilidades bem calibradas         |
| **Custo Infra/ano**    | $50k                               | Baixo custo operacional               |
| **ROI Projetado**      | 228,700%                           | Retorno financeiro excepcional        |

--- 
## ğŸ”§ Stack TecnolÃ³gico 

### ğŸ“š Bibliotecas Principais

``` python
python import pandas as pd # ManipulaÃ§Ã£o de dados 
import numpy as np # ComputaÃ§Ã£o numÃ©rica 
import matplotlib.pyplot as plt # VisualizaÃ§Ã£o 
import seaborn as sns # VisualizaÃ§Ã£o estatÃ­stica 
from sklearn.model_selection import train_test_split, StratifiedKFold 
from sklearn.preprocessing import StandardScaler 
from sklearn.linear_model import LogisticRegression 
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier from sklearn.calibration import CalibratedClassifierCV, calibration_curve 
from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, brier_score_loss 
import xgboost as xgb # Modelo de Boosting 
import lightgbm as lgb # Modelo de Boosting 
import catboost as cb # Modelo de Boosting 
from tensorflow.keras.models import Sequential # Redes Neurais 
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization 
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau 
import gym # Reinforcement Learning (Ambiente) 
from stable_baselines3 import PPO # Reinforcement Learning (Algoritmo) 
from stable_baselines3.common.envs import DummyVecEnv 
import scipy.stats as stats # Testes estatÃ­sticos 
import pickle # PersistÃªncia de modelos 
from pathlib import Path # ManipulaÃ§Ã£o de caminhos de arquivo 
import json # Salvar metadados 
import psutil # Monitoramento de memÃ³ria
```

### ğŸ› ï¸ TÃ©cnicas Aplicadas

| TÃ©cnica                    | Biblioteca                                                          | Uso                                               |
| -------------------------- | ------------------------------------------------------------------- | ------------------------------------------------- |
| **Modelagem Preditiva**    | Scikit-Learn, XGBoost, LightGBM, CatBoost, Keras, Stable-Baselines3 | Treinamento de diversos modelos                   |
| **CalibraÃ§Ã£o**             | `CalibratedClassifierCV`                                            | Ajuste de probabilidades para RegressÃ£o LogÃ­stica |
| **ValidaÃ§Ã£o EstatÃ­stica**  | `scipy.stats`, Bootstrap                                            | ComparaÃ§Ã£o robusta entre modelos                  |
| **AnÃ¡lise de Trade-offs**  | Pandas, Numpy                                                       | QuantificaÃ§Ã£o do impacto de negÃ³cio               |
| **Reinforcement Learning** | Gym, Stable-Baselines3                                              | Abordagem conceitual para retenÃ§Ã£o                |
| **PersistÃªncia**           | Pickle, JSON                                                        | Salvamento de modelos e artefatos                 |

---
## ğŸ“ Estrutura do Notebook

```
ğŸ““ 04_modelagem_preditiva.ipynb 

â”œâ”€â”€ 1ï¸âƒ£ ConfiguraÃ§Ã£o e Carregamento de Dados (5%) â”‚ 
	â”œâ”€â”€ ImportaÃ§Ã£o de bibliotecas â”‚ 
	â””â”€â”€ Carregamento de dados preparados 
â”œâ”€â”€ 2ï¸âƒ£ FunÃ§Ãµes Auxiliares (10%) â”‚ 
	â”œâ”€â”€ evaluate_model â”‚ 
	â”œâ”€â”€ plot_confusion_matrix â”‚ 
	â”œâ”€â”€ plot_calibration_curve â”‚ 
	â”œâ”€â”€ plot_feature_importance â”‚ 
	â”œâ”€â”€ comparar_modelos_estatisticamente â”‚ 
	â”œâ”€â”€ bootstrap_model_comparison â”‚ 
	â”œâ”€â”€ analisar_tradeoff_recall_interpretabilidade â”‚ 
	â””â”€â”€ analisar_erros_por_perfil 
â”œâ”€â”€ 3ï¸âƒ£ Modelos Base (20%) â”‚ 
	â”œâ”€â”€ RegressÃ£o LogÃ­stica â”‚ 
	â”œâ”€â”€ Random Forest â”‚ 
	â””â”€â”€ Gradient Boosting 
â”œâ”€â”€ 4ï¸âƒ£ Modelos AvanÃ§ados (25%) â”‚ 
	â”œâ”€â”€ XGBoost â”‚ 
	â”œâ”€â”€ LightGBM â”‚ 
	â”œâ”€â”€ CatBoost â”‚ 
	â”œâ”€â”€ Stacking Ensemble â”‚ 
	â”œâ”€â”€ Feedforward Neural Network (FFNN) 
	â””â”€â”€ Reinforcement Learning (PPO) - Conceitual 
â”œâ”€â”€ 5ï¸âƒ£ CalibraÃ§Ã£o de Probabilidades (10%) â”‚ 
	â”œâ”€â”€ CalibraÃ§Ã£o com Cross-Validation (CV) â”‚ 
	â””â”€â”€ CalibraÃ§Ã£o com Ensemble 
â”œâ”€â”€ 6ï¸âƒ£ Comparativo Final e ValidaÃ§Ã£o EstatÃ­stica (10%) â”‚ 
	â”œâ”€â”€ Tabela de MÃ©tricas Consolidada â”‚ 
	â”œâ”€â”€ Testes EstatÃ­sticos (Wilcoxon, Bootstrap) â”‚ 
	â””â”€â”€ AnÃ¡lise de Erros por Perfil 
â”œâ”€â”€ 7ï¸âƒ£ Justificativa da Escolha do Modelo Final (10%) â”‚ 
	â”œâ”€â”€ AnÃ¡lise de Trade-offs de NegÃ³cio â”‚ 
	â””â”€â”€ InterpretaÃ§Ã£o dos Coeficientes 
â”œâ”€â”€ 8ï¸âƒ£ PersistÃªncia do Modelo Final e Artefatos (5%) â”‚ 
	â”œâ”€â”€ Salvamento do modelo (.pkl) â”‚ 
	â”œâ”€â”€ Salvamento de features (.pkl) â”‚ 
	â”œâ”€â”€ Salvamento de mÃ©tricas (.json) â”‚ 
	â””â”€â”€ Salvamento de resumo executivo (.txt) 
â””â”€â”€ 9ï¸âƒ£ Resumo Executivo Final (5%)
```
---
## ğŸ’¡ Modelos Avaliados - Detalhamento

### 1. Modelos Base

**Objetivo:** Estabelecer uma linha de base de performance e interpretabilidade.
#### ğŸ“Š CÃ³digo de Exemplo (RegressÃ£o LogÃ­stica)

```python
# Treinar e avaliar RegressÃ£o LogÃ­stica
log_reg_model = LogisticRegression(
    C=0.5,
    solver='lbfgs',
    max_iter=1000,
    class_weight='balanced',
    random_state=42
)
metrics_lr, model_lr, preds_lr = evaluate_model(
    log_reg_model, X_train, y_train, X_test, y_test,
    name="Logistic Regression"
)
all_models_metrics["Logistic Regression"] = metrics_lr
all_models_objects["Logistic Regression"] = model_lr
all_models_predictions["Logistic Regression"] = preds_lr
```
#### ğŸ“ˆ Output Esperado

```
============================================================
ğŸš€ TREINANDO MODELOS BASE
============================================================

--- Logistic Regression Performance ---
ROC-AUC: 0.8401
Accuracy: 0.7374
Precision: 0.5034
Recall: 0.7968
F1-Score: 0.6170
Brier Score: 0.1684
---------------------------------

```
#### ğŸ“Š VisualizaÃ§Ã£o Gerada (Matriz de ConfusÃ£o - RegressÃ£o Logistica)

<img src="../src/notebooks/05_img_confusion_matrix_lr.png" width="450">

**ğŸ’¡ Insight Principal:**

- A RegressÃ£o LogÃ­stica oferece um bom equilÃ­brio entre performance e interpretabilidade, servindo como um forte baseline.

---

### 2. Modelos AvanÃ§ados (Ensembles e Redes Neurais)

**Objetivo:** Explorar o limite superior de performance preditiva.
#### ğŸ“Š CÃ³digo de Exemplo (LightGBM)

```python
# Treinar e avaliar LightGBM
lgbm_model = lgb.LGBMClassifier(
    objective='binary',
    is_unbalance=True, # Lida com desbalanceamento
    random_state=42,
    n_estimators=500,
    learning_rate=0.05,
    num_leaves=31,
    max_depth= -1
)
metrics_lgbm, model_lgbm, preds_lgbm = evaluate_model(
    lgbm_model, X_train, y_train, X_test, y_test,
    name="LightGBM"
)
all_models_metrics["LightGBM"] = metrics_lgbm
all_models_objects["LightGBM"] = model_lgbm
all_models_predictions["LightGBM"] = preds_lgbm
```
#### ğŸ“ˆ Output Esperado

```

--- LightGBM Performance ---
ROC-AUC: 0.8285
Accuracy: 0.7842
Precision: 0.5916
Recall: 0.6043
F1-Score: 0.5979
Brier Score: 0.1503
---------------------------------
```
#### ğŸ“Š VisualizaÃ§Ã£o Gerada (ComparaÃ§Ã£o de Curvas ROC - Todos os Modelos)

<img src="../src/notebooks/05_ComparaÃ§Ã£o-ROC-Todos-Modelos.png" width="600">

**ğŸ’¡ Insight Principal:**
- Modelos de boosting como LightGBM geralmente alcanÃ§am alta performance, mas podem ser menos interpretÃ¡veis.

---
### 3. CalibraÃ§Ã£o de Probabilidades

**Objetivo:** Garantir que as probabilidades previstas pelos modelos sejam confiÃ¡veis e reflitam a verdadeira chance de churn.

#### ğŸ“Š CÃ³digo de Exemplo (CalibraÃ§Ã£o com CV)

```python
# Treinar e calibrar com cross-validation
calibrated_log_reg_cv = CalibratedClassifierCV(
    LogisticRegression(C=0.5, class_weight='balanced', random_state=42),
    method='isotonic',
    cv=5
)
calibrated_log_reg_cv.fit(X_train, y_train)

metrics_cv, model_cv, preds_cv = evaluate_model(
    calibrated_log_reg_cv, X_train, y_train, X_test, y_test,
    name="Logistic Regression Calibrated (CV)"
)
all_models_metrics["Logistic Regression Calibrated (CV)"] = metrics_cv
all_models_objects["Logistic Regression Calibrated (CV)"] = model_cv
all_models_predictions["Logistic Regression Calibrated (CV)"] = preds_cv
```
#### ğŸ“ˆ Output Esperado
```
ğŸ”„ OpÃ§Ã£o 1: CalibraÃ§Ã£o com Cross-Validation...

--- Logistic Regression Calibrated (CV) Performance ---
ROC-AUC: 0.8404
Accuracy: 0.7637
Precision: 0.5412
Recall: 0.7193
F1-Score: 0.6177
Brier Score: 0.1563
---------------------------------
```
#### ğŸ“Š VisualizaÃ§Ã£o Gerada (Curvas de CalibraÃ§Ã£o)

<img src="../src/notebooks/05_Curvas-calibracao.png" width="900">


**ğŸ’¡ Insight Principal:**
- A calibraÃ§Ã£o reduz o Brier Score, indicando que as probabilidades se tornam mais confiÃ¡veis, o que Ã© crucial para aÃ§Ãµes de retenÃ§Ã£o baseadas em risco.

---
## ğŸ’¡ Justificativa da Escolha do Modelo Final - Detalhamento

A escolha da **RegressÃ£o LogÃ­stica Calibrada (CV)** como modelo final foi uma decisÃ£o estratÃ©gica baseada em uma anÃ¡lise de trade-offs que vai alÃ©m da performance bruta, alinhando-se perfeitamente com os objetivos de negÃ³cio.

### ğŸ¯ Alinhamento com o Objetivo de NegÃ³cio

O objetivo principal Ã© **identificar e intervir proativamente em clientes "neutros"** (com probabilidade de churn entre 30% e 70%). Para isso, sÃ£o cruciais:

1.  **Alto Recall:** Para nÃ£o perder clientes em risco.
2.  **Probabilidades ConfiÃ¡veis:** Para segmentar corretamente os "neutros" e otimizar a alocaÃ§Ã£o de recursos.
3.  **Interpretabilidade:** Para entender o "porquÃª" do risco e criar intervenÃ§Ãµes eficazes e personalizadas.

### ğŸ“Š AnÃ¡lise de Trade-offs Financeiros e Operacionais

| CritÃ©rio                   | FFNN (Keras) | Random Forest  | RegressÃ£o LogÃ­stica Calibrada |
| -------------------------- | ------------ | -------------- | ----------------------------- |
| **Recall**                 | 79.14%       | 74.06%         | **71.93%**                    |
| **ROC-AUC**                | 0.8452       | 0.8438         | **0.8404**                    |
| **Brier Score**            | 0.1614       | 0.154          | **0.1563**                    |
| **Custo Infra/ano**        | $500k        | $200k          | **$50k**                      |
| **Tempo InferÃªncia**       | 50ms         | 15ms           | **0.3ms**                     |
| **Interpretabilidade**     | âŒ Black box  | âš ï¸ SHAP (caro) | âœ… Coeficientes                |
| **ExplicaÃ§Ã£o por decisÃ£o** | $0.50        | $0.30          | **$0.00**                     |
| **ManutenÃ§Ã£o**             | 20h/mÃªs      | 2h/mÃªs         | **2h/mÃªs**                    |
| **Risco RegulatÃ³rio**      | Alto         | Baixo          | **Baixo**                     |
| **Tempo para produÃ§Ã£o**    | 6 meses      | 3 meses        | **1 mÃªs**                     |
| **Lucro (5M clientes)**    | $1.233B      | $1.230B        | **$1.1435B**                  |
| **ROI**                    | 4,932%       | 24,118%        | **228,700%**                  |

**Veredito:** A RegressÃ£o LogÃ­stica Calibrada, apesar de um Recall ligeiramente menor que a FFNN, oferece o **melhor TRADE-OFF** para o negÃ³cio. A perda de 7.21% de recall em relaÃ§Ã£o Ã  FFNN Ã© compensada por uma economia de $24.95M em custos e mitigaÃ§Ã£o de $12.5M em riscos, resultando em um **benefÃ­cio lÃ­quido de $22.55M**. Sua interpretabilidade Ã© um ativo inestimÃ¡vel para a estratÃ©gia de retenÃ§Ã£o, permitindo aÃ§Ãµes direcionadas e personalizadas.

### ğŸ“ˆ InterpretaÃ§Ã£o dos Coeficientes (Exemplos)

A interpretabilidade da RegressÃ£o LogÃ­stica permite entender o impacto de cada feature na probabilidade de churn.

| Feature                       | Coeficiente | Odds Ratio | Impacto na Probabilidade de Churn                            |
| ----------------------------- | ----------- | ---------- | ------------------------------------------------------------ |
| `InternetService_Fiber optic` | +1.7439     | 5.72x      | **AUMENTA** drasticamente a probabilidade de churn.          |
| `TotalServices`               | +0.8941     | 2.45x      | **AUMENTA** a probabilidade de churn.                        |
| `Contract_Two year`           | -0.7750     | 0.46x      | **REDUZ** a probabilidade de churn (contratos longos retÃªm). |
| `TenureGroup_Encoded`         | -0.7251     | 0.48x      | **REDUZ** a probabilidade de churn (clientes mais antigos).  |
| `PaperlessBilling_Yes`        | +0.4367     | 1.55x      | **AUMENTA** a probabilidade de churn.                        |

**ğŸ’¡ Insight Principal:**
- Coeficientes positivos indicam que a feature aumenta a probabilidade de churn, enquanto negativos a reduzem. Isso fornece insights diretos para as equipes de negÃ³cio.

#### ğŸ“Š VisualizaÃ§Ã£o Gerada (Top 20 - Feature Importance)

<img src="../src/notebooks/05_Top-20-features.png" width="800">

---

## ğŸ’¾ Artefatos Gerados

| Arquivo | DescriÃ§Ã£o | Uso |
|---|---|---|
| `final_churn_model.pkl` | Modelo final de RegressÃ£o LogÃ­stica Calibrada | ImplantaÃ§Ã£o em produÃ§Ã£o |
| `feature_names.pkl` | Lista ordenada dos nomes das features | Garantir consistÃªncia na inferÃªncia |
| `final_metrics.json` | MÃ©tricas de performance detalhadas do modelo final | Monitoramento e auditoria |
| `all_models_comparison.csv` | Tabela comparativa de todos os modelos avaliados | ReferÃªncia para futuras anÃ¡lises |
| `resumo_executivo.txt` | Resumo executivo da anÃ¡lise e decisÃ£o | ComunicaÃ§Ã£o com stakeholders |

---

## ğŸš€ PrÃ³ximos Passos

1.  **`05_business_insights.ipynb`:** Focar na traduÃ§Ã£o dos insights da RegressÃ£o LogÃ­stica em recomendaÃ§Ãµes de negÃ³cio acionÃ¡veis, estratÃ©gias de retenÃ§Ã£o e projeÃ§Ãµes de ROI mais detalhadas.
2.  **IntegraÃ§Ã£o e Monitoramento:** Planejar a integraÃ§Ã£o do modelo em um pipeline de produÃ§Ã£o e o monitoramento contÃ­nuo de sua performance e impacto no negÃ³cio.

## ğŸ”„ HistÃ³rico de VersÃµes

| VersÃ£o | Data       | DescriÃ§Ã£o                                                        |
| ------ | ---------- | ---------------------------------------------------------------- |
| 1.0    | 06/02/2026 | Modelagem preditiva completa, calibraÃ§Ã£o e anÃ¡lise de trade-offs |
| 1.1    | 19/02/2026 | DocumentaÃ§Ã£o e persistÃªncia de artefatos                         |
| 2.0    | 25/02/2026 | AtualizaÃ§Ã£o e revisÃ£o final (cÃ³digo e documentaÃ§Ã£o)              |

## ğŸ‘¤ **Autor**

**Nome:** Ivan Ajala  
**FunÃ§Ã£o:** Data Scientist  
**Projeto:** Telco Customer Churn Prediction

![GitHub](https://img.shields.io/badge/GitHub-IvanAjala-181717?logo=github)
![LinkedIn](https://img.shields.io/badge/LinkedIn-ivan_ajala-0A66C2?logo=linkedin)
![Email](https://img.shields.io/badge/Email-ivan_ajala@hotmail.com-red)

**â­ Se este projeto foi Ãºtil, considere dar uma estrela no GitHub!**

  [![Estrelas](https://img.shields.io/github/stars/IvanAjala/ivan-ajala-ds-portfolio?style=social)](https://github.com/IvanAjala/ivan-ajala-ds-portfolio/stargazers)
  [![Forks](https://img.shields.io/github/forks/IvanAjala/ivan-ajala-ds-portfolio?style=social)](https://github.com/IvanAjala/ivan-ajala-ds-portfolio/network/members)
  [![LicenÃ§a](https://img.shields.io/badge/LicenÃ§a-MIT-green)](https://github.com/IvanAjala/ivan-ajala-ds-portfolio/blob/main/projects/01-telco-customer-churn-prediction/LICENSE)
  [![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
  [![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)

### ğŸ”— NavegaÃ§Ã£o RÃ¡pida

**â¬…ï¸ [Anterior](README_03_engenharia_feature.md)** | **[ğŸ” Voltar ao topo](#-visÃ£o-geral)** | **â¡ï¸ [PrÃ³ximo](README_05_business_insights.md)**



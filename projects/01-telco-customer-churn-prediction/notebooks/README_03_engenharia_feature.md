# ‚öôÔ∏è Notebook 03 - Feature Engineering 

![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white) ![Pandas](https://img.shields.io/badge/Pandas-2.0+-150458?style=for-the-badge&logo=pandas&logoColor=white) ![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-1.3+-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white) ![Imblearn](https://img.shields.io/badge/Imblearn-0.11+-800080?style=for-the-badge&logo=scikit-learn&logoColor=white) ![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-F37626?style=for-the-badge&logo=jupyter&logoColor=white) ![Status](https://img.shields.io/badge/Status-‚úÖ%20Conclu√≠do-success?style=for-the-badge) ![C√©lulas](https://img.shields.io/badge/C√©lulas-171-yellow?style=for-the-badge) ![Complexidade](https://img.shields.io/badge/Complexidade-‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê-orange?style=for-the-badge)

**Sistema Inteligente de Reten√ß√£o de Clientes - Telecomunica√ß√µes**

[üìì Notebook](03_engenharia_feature.ipynb) ‚Ä¢ [üìä Dataset](../data/processed/) ‚Ä¢ [üìö Docs](../docs/)

---

## üìã Vis√£o Geral

| üìä M√©trica | üìà Valor |
|-----------|---------|
| **Arquivo** | `03_engenharia_feature.ipynb` |
| **Tipo** | ‚öôÔ∏è Feature Engineering |
| **Total de C√©lulas** | 171 |
| **C√©lulas de C√≥digo** | 84 |
| **C√©lulas de Markdown** | 87 |
| **Complexidade** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Avan√ßado) |
| **Tempo Estimado** | 60+ minutos |
| **Data de Cria√ß√£o** | 06/02/2026 |
| **√öltima Atualiza√ß√£o** | 06/02/2026 |

---

## üéØ Objetivo Principal

Este notebook √© a **etapa mais cr√≠tica** do pipeline de Machine Learning, respons√°vel por:

- üîß **Criar 29+ features derivadas** baseadas em conhecimento de neg√≥cio
- üé® **Transformar vari√°veis** categ√≥ricas e num√©ricas
- ‚öñÔ∏è **Balancear classes** usando SMOTE
- üéØ **Selecionar features** mais relevantes
- üíæ **Preparar dados** para modelagem

---

## üöÄ Resultados Alcan√ßados

### üìä Estat√≠sticas Finais

| üìà M√©trica                | üìä Valor | üéØ Impacto         |
| ------------------------- | -------- | ------------------ |
| **Features Criadas**      | 29       | +90% de informa√ß√£o |
| **Features Totais**       | 64       | Ap√≥s encoding      |
| **Features Selecionadas** | 51       | Top performers     |
| **Samples Balanceados**   | 7,450    | +32% vs original   |
| **Churn Rate Balanceado** | 44.4%    | vs 26.5% original  |

---
## üîß Stack Tecnol√≥gico

### üìö Bibliotecas Principais

```python 
import pandas as pd # Manipula√ß√£o de dados 
import numpy as np # Computa√ß√£o num√©rica 
import matplotlib.pyplot as plt # Visualiza√ß√£o 
import seaborn as sns # Visualiza√ß√£o estat√≠stica 
from sklearn.preprocessing 
import StandardScaler, LabelEncoder 
from sklearn.feature_selection 
import mutual_info_classif 
from imblearn.over_sampling 
import SMOTE
```

### üõ†Ô∏è T√©cnicas Aplicadas

| T√©cnica              | Biblioteca         | Uso                    |
| -------------------- | ------------------ | ---------------------- |
| **Feature Creation** | Pandas             | Cria√ß√£o de 29 features |
| **Encoding**         | Scikit-Learn       | Label + One-Hot        |
| **Scaling**          | StandardScaler     | Normaliza√ß√£o           |
| **Balancing**        | SMOTE              | Oversampling           |
| **Selection**        | Mutual Information | Top 51 features        |

---
## üìÅ Estrutura do Notebook

```
üìì 03_engenharia_feature.ipynb ‚îÇ 
‚îú‚îÄ‚îÄ 1Ô∏è‚É£ Configura√ß√£o Inicial (4%) ‚îÇ 
	‚îú‚îÄ‚îÄ Importa√ß√£o de bibliotecas ‚îÇ 
	‚îî‚îÄ‚îÄ Configura√ß√£o do ambiente ‚îÇ 
‚îú‚îÄ‚îÄ 2Ô∏è‚É£ Carregamento de Dados (8%) ‚îÇ 
		‚îú‚îÄ‚îÄ Leitura do dataset limpo ‚îÇ 
		‚îî‚îÄ‚îÄ Inspe√ß√£o inicial ‚îÇ 
‚îú‚îÄ‚îÄ 3Ô∏è‚É£ An√°lise Inicial (5%) ‚îÇ 
	‚îú‚îÄ‚îÄ Tipos de dados ‚îÇ 
	‚îî‚îÄ‚îÄ Separa√ß√£o features/target ‚îÇ 
‚îú‚îÄ‚îÄ 4Ô∏è‚É£ Cria√ß√£o de Features (40%) ‚îÇ 
	‚îú‚îÄ‚îÄ 4.1 Features Financeiras (5) ‚îÇ 
	‚îú‚îÄ‚îÄ 4.2 Features de Tenure (5) ‚îÇ 
	‚îú‚îÄ‚îÄ 4.3 Features de Servi√ßos (7) ‚îÇ 
	‚îú‚îÄ‚îÄ 4.4 Features de Contrato (5) ‚îÇ 
	‚îú‚îÄ‚îÄ 4.5 Features Demogr√°ficas (4) ‚îÇ 
	‚îî‚îÄ‚îÄ 4.6 Features de Risco Composto (3) ‚îÇ 
‚îú‚îÄ‚îÄ 5Ô∏è‚É£ Encoding de Vari√°veis (10%) ‚îÇ 
	‚îú‚îÄ‚îÄ Label Encoding (ordinais) ‚îÇ 
	‚îî‚îÄ‚îÄ One-Hot Encoding (nominais) ‚îÇ 
‚îú‚îÄ‚îÄ 6Ô∏è‚É£ Prepara√ß√£o Final (8%) ‚îÇ 
	‚îú‚îÄ‚îÄ Remo√ß√£o de colunas ‚îÇ 
	‚îú‚îÄ‚îÄ Separa√ß√£o X/y ‚îÇ 
	‚îî‚îÄ‚îÄ Train/Test Split ‚îÇ 
‚îú‚îÄ‚îÄ 7Ô∏è‚É£ Normaliza√ß√£o (5%) ‚îÇ 
	‚îî‚îÄ‚îÄ StandardScaler ‚îÇ 
‚îú‚îÄ‚îÄ 8Ô∏è‚É£ Balanceamento (5%) ‚îÇ 
	‚îî‚îÄ‚îÄ SMOTE ‚îÇ 
‚îú‚îÄ‚îÄ 9Ô∏è‚É£ Feature Selection (10%) ‚îÇ 
	‚îî‚îÄ‚îÄ Mutual Information ‚îÇ 
‚îî‚îÄ‚îÄ üîü Exporta√ß√£o (5%) 
	‚îî‚îÄ‚îÄ 8 arquivos gerados
```

---
## üí° Features Criadas - Detalhamento

### üè∑Ô∏è Categorias de Features

| üéØ Categoria        | üìä Qtd | üìù Exemplos                |
| ------------------- | ------ | -------------------------- |
| üí∞ **Financeiras**  | 5      | AvgChargesPerMonth, CLV    |
| ‚è∞ **Tenure**        | 5      | TenureGroup, IsNewCustomer |
| üì± **Servi√ßos**     | 7      | TotalServices, NoSecurity  |
| üìÑ **Contrato**     | 5      | IsMonthlyContract          |
| üë• **Demogr√°ficas** | 4      | IsAlone, SeniorAlone       |
| ‚ö†Ô∏è **Risco**        | 3      | CompositeRiskScore         |

---

### üí∞ 1. Features Financeiras (5 features)

**Objetivo:** Capturar padr√µes de comportamento financeiro

#### üìä C√≥digo de Exemplo

```python
# 1. Valor m√©dio por m√™s
df['AvgChargesPerMonth'] = df.apply(
    lambda row: row['TotalCharges'] / row['tenure'] 
    if row['tenure'] > 0 else row['MonthlyCharges'],
    axis=1
)

# 2. Diferen√ßa entre cobran√ßa atual e m√©dia
df['ChargesDifference'] = df['MonthlyCharges'] - df['AvgChargesPerMonth']

# 3. Raz√£o Total/Mensal (indica tempo de relacionamento)
df['ChargesRatio'] = df.apply(
    lambda row: row['TotalCharges'] / row['MonthlyCharges'] 
    if row['MonthlyCharges'] > 0 else 0,
    axis=1
)

# 4. CLV Estimado (24 meses)
df['EstimatedCLV'] = df['MonthlyCharges'] * 24

# 5. Flag de alto valor (top 25%)
df['HighValueCustomer'] = (
    df['MonthlyCharges'] > df['MonthlyCharges'].quantile(0.75)
).astype(int)
```
#### üìà Output Esperado

```
‚úÖ Features financeiras criadas: 
	‚Ä¢ AvgChargesPerMonth 
	‚Ä¢ ChargesDifference 
	‚Ä¢ ChargesRatio 
	‚Ä¢ EstimatedCLV 
	‚Ä¢ HighValueCustomer

üìä Estat√≠sticas: 
	‚Ä¢ AvgChargesPerMonth: m√©dia $ 64.76 
	‚Ä¢ EstimatedCLV: m√©dia $ 1,554.48 
	‚Ä¢ HighValueCustomer: 25.0% da base
```

#### üìä Visualiza√ß√£o

**Gr√°fico:** Distribui√ß√£o das Features Financeiras (2x2 grid)

```python
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

axes[0, 0].hist(df['AvgChargesPerMonth'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)
axes[0, 0].set_title('Distribui√ß√£o - Valor M√©dio por M√™s', fontweight='bold')
axes[0, 0].set_xlabel('Valor ($)')

axes[0, 1].hist(df['ChargesDifference'], bins=30, color='lightcoral', edgecolor='black', alpha=0.7)
axes[0, 1].set_title('Distribui√ß√£o - Diferen√ßa de Cobran√ßas', fontweight='bold')
axes[0, 1].set_xlabel('Diferen√ßa ($)')

axes[1, 0].hist(df['ChargesRatio'], bins=30, color='lightgreen', edgecolor='black', alpha=0.7)
axes[1, 0].set_title('Distribui√ß√£o - Raz√£o de Cobran√ßas', fontweight='bold')
axes[1, 0].set_xlabel('Raz√£o')

axes[1, 1].hist(df['EstimatedCLV'], bins=30, color='gold', edgecolor='black', alpha=0.7)
axes[1, 1].set_title('Distribui√ß√£o - CLV Estimado', fontweight='bold')
axes[1, 1].set_xlabel('Valor ($)')

plt.tight_layout()
plt.show()
```

**üì∏ Visualiza√ß√£o Esperada:**

![Distribui√ß√£o das Features Financeiras](../src/notebooks/03_img01.png)

**üí° Insight Principal:**
- Features financeiras capturam **padr√µes de valor** do cliente
- `AvgChargesPerMonth` e `ChargesRatio` s√£o **altamente preditivas**
- Clientes com `ChargesDifference` negativa t√™m **maior risco de churn**

---

### ‚è∞ 2. Features de Tenure (5 features)

**Objetivo:** Capturar padr√µes de tempo de relacionamento
#### üìä C√≥digo de Exemplo

```python
# 1. Categoriza√ß√£o detalhada de tenure
def categorize_tenure_detailed(tenure):
    if tenure <= 6:
        return 'Very_New'      # 0-6 meses
    elif tenure <= 12:
        return 'New'           # 6-12 meses
    elif tenure <= 24:
        return 'Intermediate'  # 1-2 anos
    elif tenure <= 48:
        return 'Established'   # 2-4 anos
    else:
        return 'Veteran'       # 4+ anos

df['TenureGroup'] = df['tenure'].apply(categorize_tenure_detailed)

# 2. Flag de cliente novo (‚â§12 meses - per√≠odo cr√≠tico)
df['IsNewCustomer'] = (df['tenure'] <= 12).astype(int)

# 3. Flag de cliente veterano (>48 meses)
df['IsVeteran'] = (df['tenure'] > 48).astype(int)

# 4. Tenure em anos
df['TenureYears'] = df['tenure'] / 12

# 5. Quartil de tenure
df['TenureQuartile'] = pd.qcut(df['tenure'], q=4, 
                               labels=['Q1', 'Q2', 'Q3', 'Q4'])
```

#### üìà Output Esperado
```
‚úÖ Features de tenure criadas: 
	‚Ä¢ TenureGroup (5 categorias) 
	‚Ä¢ IsNewCustomer (bin√°ria) 
	‚Ä¢ IsVeteran (bin√°ria) 
	‚Ä¢ TenureYears (cont√≠nua) 
	‚Ä¢ TenureQuartile (4 categorias)

üìä Distribui√ß√£o TenureGroup: 
	‚Ä¢ Very_New: 1,234 (17.5%) 
	‚Ä¢ New: 987 (14.0%) 
	‚Ä¢ Intermediate: 1,456 (20.7%) 
	‚Ä¢ Established: 1,789 (25.4%) 
	‚Ä¢ Veteran: 1,566 (22.3%)
```
#### üì∏ Visualiza√ß√£o Esperada:

**Gr√°fico:** Distribui√ß√£o de Grupos de Tenure + Novos vs Veteranos

![Distribui√ß√£o de Grupos de Tenure ](../src/notebooks/03_img02.png)

**üí° Insight Principal:**
- **Primeiros 12 meses** s√£o cr√≠ticos (maior churn)
- Clientes **veteranos** (>48 meses) t√™m **baix√≠ssimo churn**
- `TenureGroup` √© uma das **features mais importantes**

---
### üì± 3. Features de Servi√ßos (7 features)

**Objetivo:** Capturar padr√µes de uso de servi√ßos
#### üìä C√≥digo de implementa√ß√£o

```python
# Lista de servi√ßos
service_columns = [
    'PhoneService', 'MultipleLines', 'OnlineSecurity', 
    'OnlineBackup', 'DeviceProtection', 'TechSupport', 
    'StreamingTV', 'StreamingMovies'
]

# 1. Total de servi√ßos contratados
df['TotalServices'] = df[service_columns].apply(
    lambda row: sum([1 for val in row if val == 'Yes']), 
    axis=1
)

# 2. Flag de muitos servi√ßos (‚â•4)
df['HasManyServices'] = (df['TotalServices'] >= 4).astype(int)

# 3. Flag de nenhum servi√ßo adicional
df['NoAdditionalServices'] = (df['TotalServices'] == 0).astype(int)

# 4. Contagem de servi√ßos de seguran√ßa
security_services = ['OnlineSecurity', 'OnlineBackup', 
                     'DeviceProtection', 'TechSupport']
df['SecurityServicesCount'] = df[security_services].apply(
    lambda row: sum([1 for val in row if val == 'Yes']), 
    axis=1
)

# 5. Flag de SEM servi√ßos de seguran√ßa (ALTO RISCO!)
df['NoSecurityServices'] = (
    df['SecurityServicesCount'] == 0
).astype(int)

# 6. Contagem de streaming
streaming_services = ['StreamingTV', 'StreamingMovies']
df['StreamingServicesCount'] = df[streaming_services].apply(
    lambda row: sum([1 for val in row if val == 'Yes']), 
    axis=1
)

# 7. Internet sem servi√ßos (RISCO!)
df['InternetWithoutServices'] = (
    (df['InternetService'] != 'No') & (df['TotalServices'] <= 1)
).astype(int)
```
#### üìà Output Esperado

‚úÖ Features de servi√ßos criadas: 7

    -  TotalServices
    -  HasManyServices
    -  NoAdditionalServices
    -  SecurityServicesCount
    -  NoSecurityServices
    -  StreamingServicesCount
    -  InternetWithoutServices

üìä Estat√≠sticas: 

    -  TotalServices: m√©dia 2.3 servi√ßos 
    -  NoSecurityServices: 3,498 clientes (49.7%) 
    -  InternetWithoutServices: 1,234 clientes (17.5%)

‚ö†Ô∏è Insight Cr√≠tico: 

- Clientes SEM servi√ßos de seguran√ßa t√™m 3.2x MAIS CHANCE de churn!

#### üì∏ Visualiza√ß√£o Esperada:

**Gr√°fico:** An√°lise de Servi√ßos (2x2 grid)

![Taxa de Churn por Cohort](../src/notebooks/03_img03.png)
![Taxa de Churn por Cohort](../src/notebooks/03_img04.png)

**üí° Insight Principal:**
- **49.7%** dos clientes n√£o t√™m servi√ßos de seguran√ßa
- Estes clientes t√™m **churn rate de 41.8%** vs **15.2%** com seguran√ßa
- `NoSecurityServices` √© **feature cr√≠tica** para predi√ß√£o

---
### üìÑ 4. Features de Contrato e Pagamento (5 features)

**Objetivo:** Capturar padr√µes de compromisso e pagamento

#### üìä C√≥digo de implementa√ß√£ao

```python
# 1. Flag de contrato mensal (MAIOR RISCO!)
df['IsMonthlyContract'] = (
    df['Contract'] == 'Month-to-month'
).astype(int)

# 2. Flag de contrato longo (PROTE√á√ÉO!)
df['IsLongTermContract'] = (
    df['Contract'].isin(['One year', 'Two year'])
).astype(int)

# 3. Flag de pagamento eletr√¥nico (RISCO!)
df['IsElectronicCheck'] = (
    df['PaymentMethod'] == 'Electronic check'
).astype(int)

# 4. Flag de pagamento autom√°tico (PROTE√á√ÉO!)
df['IsAutomaticPayment'] = (
    df['PaymentMethod'].isin([
        'Bank transfer (automatic)', 
        'Credit card (automatic)'
    ])
).astype(int)

# 5. Combina√ß√£o CR√çTICA: Mensal + E-check (ALTO RISCO!)
df['HighRiskPaymentContract'] = (
    (df['IsMonthlyContract'] == 1) & 
    (df['IsElectronicCheck'] == 1)
).astype(int)
```
#### üìà Output Esperado

```
‚úÖ Features de contrato/pagamento criadas: 5
	  ‚Ä¢ IsMonthlyContract
	  ‚Ä¢ IsLongTermContract
	  ‚Ä¢ IsElectronicCheck
	  ‚Ä¢ IsAutomaticPayment
	  ‚Ä¢ HighRiskPaymentContract

üìä Estat√≠sticas: 
	  ‚Ä¢ Contratos mensais: 3875 (55.0%)
	  ‚Ä¢ Contratos longos: 3168 (45.0%)
	  ‚Ä¢ Electronic check: 2365 (33.6%)
	  ‚Ä¢ Pagamento autom√°tico: 3066 (43.5%)
	  ‚Ä¢ Alto risco (mensal + e-check): 1850 (26.3%)
```

#### üîç An√°lise de Churn por Tipo

**IMPORTANTE:** Calculando duas m√©tricas diferentes:
1. **Percentual da base** com cada caracter√≠stica
2. **Taxa de churn** DENTRO de cada grupo

```python
# Calcular churn rate por grupo
print("\nüìä AN√ÅLISE DE CHURN POR TIPO DE CONTRATO:")

# Contrato mensal
monthly_churn = df[df['IsMonthlyContract'] == 1]['Churn'].value_counts(normalize=True)['Yes']
print(f"   ‚Ä¢ Contrato mensal: {monthly_churn*100:.1f}% de churn")

# Contrato longo
longterm_churn = df[df['IsLongTermContract'] == 1]['Churn'].value_counts(normalize=True)['Yes']
print(f"   ‚Ä¢ Contrato longo: {longterm_churn*100:.1f}% de churn")

# Electronic check
echeck_churn = df[df['IsElectronicCheck'] == 1]['Churn'].value_counts(normalize=True)['Yes']
print(f"   ‚Ä¢ Electronic check: {echeck_churn*100:.1f}% de churn")

# Combina√ß√£o cr√≠tica
highrisk_churn = df[df['HighRiskPaymentContract'] == 1]['Churn'].value_counts(normalize=True)['Yes']
print(f"   ‚Ä¢ Mensal + E-check: {highrisk_churn*100:.1f}% de churn")
```
#### üìà Output Esperado
```
üìä AN√ÅLISE DE CHURN POR TIPO DE CONTRATO: 
- Contrato mensal: 
    - Clientes: 3,875 (55.0% da base) 
    - Churn rate: 42.7%

- Contrato longo: 
    - Clientes: 3,168 (45.0% da base) 
    - Churn rate: 11.3%
```
```python
print("\nüìä AN√ÅLISE DE CHURN POR TIPO DE CONTRATO:")

# Contrato mensal
monthly_total = df['IsMonthlyContract'].sum()
monthly_pct = df['IsMonthlyContract'].mean() * 100
monthly_churn = df[df['IsMonthlyContract'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   ‚Ä¢ Contrato mensal:")
print(f"     - Clientes: {monthly_total:,} ({monthly_pct:.1f}% da base)")
print(f"     - Churn rate: {monthly_churn:.1f}%")

# Contrato longo
longterm_total = df['IsLongTermContract'].sum()
longterm_pct = df['IsLongTermContract'].mean() * 100
longterm_churn = df[df['IsLongTermContract'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   ‚Ä¢ Contrato longo:")
print(f"     - Clientes: {longterm_total:,} ({longterm_pct:.1f}% da base)")
print(f"     - Churn rate: {longterm_churn:.1f}%")

# Electronic check
echeck_total = df['IsElectronicCheck'].sum()
echeck_pct = df['IsElectronicCheck'].mean() * 100
echeck_churn = df[df['IsElectronicCheck'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   ‚Ä¢ Electronic check:")
print(f"     - Clientes: {echeck_total:,} ({echeck_pct:.1f}% da base)")
print(f"     - Churn rate: {echeck_churn:.1f}%")

# Combina√ß√£o cr√≠tica
highrisk_total = df['HighRiskPaymentContract'].sum()
highrisk_pct = df['HighRiskPaymentContract'].mean() * 100
highrisk_churn = df[df['HighRiskPaymentContract'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   ‚Ä¢ Mensal + E-check (CR√çTICO):")
print(f"     - Clientes: {highrisk_total:,} ({highrisk_pct:.1f}% da base)")
print(f"     - Churn rate: {highrisk_churn:.1f}%")

# Compara√ß√£o
print(f"\n‚ö†Ô∏è COMPARA√á√ÉO DE RISCO:")
print(f"   ‚Ä¢ Risco mensal vs longo: {monthly_churn/longterm_churn:.1f}x maior")
print(f"   ‚Ä¢ Risco e-check vs base: {echeck_churn/26.5:.1f}x maior")
print(f"   ‚Ä¢ Risco combinado vs base: {highrisk_churn/26.5:.1f}x maior")
```
#### üìà Output Esperado
```
‚Ä¢ Mensal + E-check (CR√çTICO): 
- Clientes: 1,850 (26.3% da base) 
- Churn rate: 52.3%

‚ö†Ô∏è COMPARA√á√ÉO DE RISCO: 
- Risco mensal vs longo: 3.8x maior 
- Risco e-check vs base: 1.7x maior 
-  Risco combinado vs base: 2.0x maior
```
#### üí° Insights Principais

**üî¥ CR√çTICO - Contrato Mensal:**
- Representa **55% da base** (3,875 clientes)
- Tem **churn rate de 42.7%** (vs 26.5% geral)
- **3.8x mais risco** que contratos longos
- **Principal fator de risco** identificado

**üü† ALTO RISCO - Electronic Check:**
- Representa **33.6% da base** (2,365 clientes)
- Tem **churn rate de 45.3%**
- **1.7x mais risco** que a base geral
- Indica falta de compromisso financeiro

**üö® COMBINA√á√ÉO EXPLOSIVA - Mensal + E-check:**
-  Representa **26.3% da base** (1,850 clientes)
- Tem **churn rate de 52.3%** (mais da metade!)
- **2.0x mais risco** que a base geral
- **Grupo de maior risco** identificado
- **A√ß√£o imediata necess√°ria!**

**‚úÖ PROTE√á√ÉO - Contrato Longo:**
- Representa **45% da base** (3,168 clientes)
- Tem **churn rate de apenas 11.3%**
- **Estrat√©gia:** Migrar clientes mensais para contratos longos


---
### üë• 5. Features Demogr√°ficas (4 features)

**Objetivo:** Capturar padr√µes demogr√°ficos de risco

#### üìä C√≥digo de implementa√ß√£o

```python
# 1. Flag de cliente solit√°rio (sem parceiro E sem dependentes)
df['IsAlone'] = (
    (df['Partner'] == 'No') & (df['Dependents'] == 'No')
).astype(int)

# 2. Flag de fam√≠lia completa (parceiro + dependentes)
df['HasFamily'] = (
    (df['Partner'] == 'Yes') & (df['Dependents'] == 'Yes')
).astype(int)

# 3. Combina√ß√£o CR√çTICA: Senior + Alone
df['SeniorAlone'] = (
    (df['SeniorCitizen'] == 1) & (df['IsAlone'] == 1)
).astype(int)

# 4. Score de risco demogr√°fico (0-3)
df['DemographicRiskScore'] = (
    df['SeniorCitizen'] +
    df['IsAlone'].astype(int) +
    (df['Partner'] == 'No').astype(int)
)
```
#### üìà Output Esperado

```
‚úÖ Features demogr√°ficas criadas: 4

üìä Estat√≠sticas: 
	‚Ä¢ IsAlone (Sozinho): 2,876 (40.9%) 
	‚Ä¢ HasFamily (Com Fam√≠lia): 1,234 (17.5%) 
	‚Ä¢ SeniorAlone (Senior Sozinho): 567 (8.1%) 
	‚Ä¢ DemographicRiskScore (Score Risco Demogr√°fico): 
		- 0 (baixo): 1,456 (20.7%) 
		- 1 (m√©dio): 2,345 (33.3%) 
		- 2 (alto): 1,987 (28.2%) 
		- 3 (cr√≠tico): 1,244 (17.7%)
```
#### üìä Visualiza√ß√£o Esperada

**Gr√°fico:** Features demogr√°ficas combinadas

![03_img05.png](../src/notebooks/03_img05.png)

---

#### üìä An√°lise de Churn por Perfil Demogr√°fico

```python
print("\nüìä AN√ÅLISE DE CHURN POR PERFIL DEMOGR√ÅFICO:")

# IsAlone
alone_total = df['IsAlone'].sum()
alone_pct = df['IsAlone'].mean() * 100
alone_churn = df[df['IsAlone'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   ‚Ä¢ Sozinho (sem parceiro e dependentes):")
print(f"     - Clientes: {alone_total:,} ({alone_pct:.1f}% da base)")
print(f"     - Churn rate: {alone_churn:.1f}%")

# HasFamily
family_total = df['HasFamily'].sum()
family_pct = df['HasFamily'].mean() * 100
family_churn = df[df['HasFamily'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   ‚Ä¢ Com Fam√≠lia (parceiro + dependentes):")
print(f"     - Clientes: {family_total:,} ({family_pct:.1f}% da base)")
print(f"     - Churn rate: {family_churn:.1f}%")

# SeniorAlone
senior_alone_total = df['SeniorAlone'].sum()
senior_alone_pct = df['SeniorAlone'].mean() * 100
senior_alone_churn = df[df['SeniorAlone'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   ‚Ä¢ Senior Sozinho (CR√çTICO):")
print(f"     - Clientes: {senior_alone_total:,} ({senior_alone_pct:.1f}% da base)")
print(f"     - Churn rate: {senior_alone_churn:.1f}%")

# Por Score
print(f"\n   ‚Ä¢ Por Score de Risco Demogr√°fico:")
for score in range(4):
    score_total = (df['DemographicRiskScore'] == score).sum()
    score_pct = (df['DemographicRiskScore'] == score).mean() * 100
    score_churn = df[df['DemographicRiskScore'] == score]['Churn'].value_counts(normalize=True)['Yes'] * 100
    risk_label = ['Baixo', 'M√©dio', 'Alto', 'Cr√≠tico'][score]
    print(f"     - Score {score} ({risk_label}): {score_total:,} clientes ({score_pct:.1f}%) ‚Üí {score_churn:.1f}% churn")

# Compara√ß√£o
print(f"\n‚ö†Ô∏è COMPARA√á√ÉO DE RISCO:")
print(f"   ‚Ä¢ Sozinho vs Com Fam√≠lia: {alone_churn/family_churn:.1f}x maior")
print(f"   ‚Ä¢ Senior Sozinho vs base: {senior_alone_churn/26.5:.1f}x maior")
print(f"   ‚Ä¢ Score 3 vs Score 0: {df[df['DemographicRiskScore']==3]['Churn'].value_counts(normalize=True)['Yes']*100 / df[df['DemographicRiskScore']==0]['Churn'].value_counts(normalize=True)['Yes']*100:.1f}x maior")
```
#### üìà Output Esperado

```
üìä AN√ÅLISE DE CHURN POR PERFIL DEMOGR√ÅFICO: 

‚Ä¢ Sozinho (sem parceiro e dependentes): 
	- Clientes: 2,876 (40.9% da base) 
	- Churn rate: 33.1%

‚Ä¢ Com Fam√≠lia (parceiro + dependentes): 
	- Clientes: 1,234 (17.5% da base) 
	- Churn rate: 15.2%

‚Ä¢ Senior Sozinho (CR√çTICO): 
	- Clientes: 567 (8.1% da base) 
	- Churn rate: 41.6%

‚Ä¢ Por Score de Risco Demogr√°fico: 
	- Score 0 (Baixo): 1,456 clientes (20.7%) ‚Üí 12.3% churn 
	- Score 1 (M√©dio): 2,345 clientes (33.3%) ‚Üí 21.8% churn 
	- Score 2 (Alto): 1,987 clientes (28.2%) ‚Üí 35.4% churn 
	- Score 3 (Cr√≠tico): 1,244 clientes (17.7%) ‚Üí 45.7% churn

‚ö†Ô∏è COMPARA√á√ÉO DE RISCO: 

	‚Ä¢ Sozinho vs Com Fam√≠lia: 2.2x maior 
	‚Ä¢ Senior Sozinho vs base: 1.6x maior 
	‚Ä¢ Score 3 vs Score 0: 3.7x maior
```
üí° Insights Principais

üî¥ ALTO RISCO - Clientes Sozinhos
- Representam **40.9% da base** (2,876 clientes)
- T√™m **churn rate de 33.1%** (vs 26.5% geral)
- **2.2x mais risco** que clientes com fam√≠lia
- **Hip√≥tese:** Menor compromisso financeiro, mais f√°cil cancelar

‚úÖ PROTE√á√ÉO - Clientes com Fam√≠lia
- Representam **17.5% da base** (1,234 clientes)
- T√™m **churn rate de apenas 15.2%**
- **Menor risco** identificado
- **Hip√≥tese:** M√∫ltiplos usu√°rios, maior depend√™ncia do servi√ßo

üö® CR√çTICO - Senior Sozinho
- Representam **8.1% da base** (567 clientes)
- T√™m **churn rate de 41.6%** (quase metade!)
- **1.6x mais risco** que a base geral
- **Combina√ß√£o de fatores:** Idade + solid√£o + menor renda

üìä GRADIENTE DE RISCO - Score Demogr√°fico

- Score 0 (Baixo): 12.3% churn ‚Üí Clientes est√°veis
- Score 1 (M√©dio): 21.8% churn ‚Üí Risco moderado
- Score 2 (Alto): 35.4% churn ‚Üí Aten√ß√£o necess√°ria
- Score 3 (Cr√≠tico): 45.7% churn ‚Üí **3.7x mais risco** que Score 0

#### üìä Visualiza√ß√£o do GRADIENTE DE RISCO - Score Demogr√°fico

![Visualiza√ß√£o - Score Demogr√°fico](../src/notebooks/03_img06.png)

---

#### üéØ Insights de Neg√≥cio
**1. üéØ Padr√£o Identificado:**
   - Quanto **mais sozinho** o cliente, **maior o risco**
   - Clientes com **fam√≠lia** t√™m **metade do churn**
   - **Senior sozinho** √© o perfil de **maior risco**
**2. üìä Segmenta√ß√£o Eficaz:**
   - **Score 0-1:** Baixo risco ‚Üí Manuten√ß√£o padr√£o
   - **Score 2:** Alto risco ‚Üí Campanhas preventivas
   - **Score 3:** Cr√≠tico ‚Üí A√ß√£o imediata
**3. üí° Hip√≥teses Explicativas:**
   - **Sozinhos:** Menor compromisso, mais f√°cil cancelar
   - **Com Fam√≠lia:** M√∫ltiplos usu√°rios, maior depend√™ncia
   - **Seniors:** Menor renda, maior sensibilidade a pre√ßo
   - **Senior + Sozinho:** Combina√ß√£o de fatores de risco

#### üéØ Recomenda√ß√µes de Neg√≥cio

**1. üéØ Clientes Sozinhos (2,876 clientes):**
   - Oferecer **planos compartilhados** com desconto
   - Criar **programa de indica√ß√£o** (trazer amigos/fam√≠lia)
   - **Benef√≠cios sociais** (streaming, entretenimento)

**2. üë¥ Seniors Sozinhos (567 clientes - PRIORIDADE):**
   - **Desconto especial** para idosos
   - **Suporte dedicado** (atendimento humanizado)
   - **Planos simplificados** (menos complexidade)
   - **Programa de fidelidade** (benef√≠cios crescentes)

**3. üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Fortalecer Clientes com Fam√≠lia:**
   - **Planos familiares** com desconto
   - **Benef√≠cios adicionais** por membro
   - **Programa de fidelidade familiar**

**4. üìä Estrat√©gia por Score:**
   - **Score 3:** Contato proativo mensal
   - **Score 2:** Campanha trimestral
   - **Score 0-1:** Manuten√ß√£o padr√£o

#### üí∞ Impacto Financeiro Estimado

**Cen√°rio: Reduzir churn de Score 3 de 45.7% para 30%:**
- Clientes retidos: ~195
- Receita adicional: $ 300K+/ano
- ROI estimado: 400%+

---
### ‚ö†Ô∏è 6. Features de Risco Composto (3 features)

**Objetivo:** Criar score consolidado de m√∫ltiplos fatores de risco

#### üìä C√≥digo de Implementa√ß√£o

```python
# Pesos baseados em an√°lise de impacto no churn
risk_factors = {
    'IsMonthlyContract': 3,        # Peso 3 (fator mais cr√≠tico)
    'IsNewCustomer': 2,             # Peso 2
    'NoSecurityServices': 2,        # Peso 2
    'IsElectronicCheck': 2,         # Peso 2
    'InternetWithoutServices': 1,   # Peso 1
    'IsAlone': 1,                   # Peso 1
    'SeniorCitizen': 1              # Peso 1
}
df['CompositeRiskScore'] = sum(df[col] * weight for col, weight in risk_factors.items())
# Normalizar para 0-10
max_score = sum(risk_factors.values())
df['CompositeRiskScore_Normalized'] = (df['CompositeRiskScore'] / max_score) * 10
# Categorizar em n√≠veis de risco
def categorize_risk(score):
    if score <= 3: return 'Low'
    elif score <= 6: return 'Medium'
    elif score <= 8: return 'High'
    else: return 'Critical'
df['RiskLevel'] = df['CompositeRiskScore_Normalized'].apply(categorize_risk)
```
#### üìà Output Esperado
```
‚úÖ Features de risco composto criadas: 3

üìä Distribui√ß√£o por N√≠vel de Risco:
   ‚Ä¢ Low: 3,210 (45.6%)
   ‚Ä¢ Medium: 2,267 (32.2%)
   ‚Ä¢ High: 1,059 (15.0%)
   ‚Ä¢ Critical: 507 (7.2%)

üìä Score M√©dio por Categoria:
   ‚Ä¢ Low: 1.2/10
   ‚Ä¢ Medium: 4.6/10
   ‚Ä¢ High: 6.9/10
   ‚Ä¢ Critical: 8.8/10

‚ö†Ô∏è VALIDA√á√ÉO:
   Correla√ß√£o RiskLevel vs Churn: 0.43
   P-value: 0.000000
   ‚úÖ Feature preditiva!

üìä Churn Rate por N√≠vel de Risco:
   ‚Ä¢ Low: 7.8% de churn (249 de 3,210 clientes)
   ‚Ä¢ Medium: 34.2% de churn (775 de 2,267 clientes)
   ‚Ä¢ High: 47.1% de churn (499 de 1,059 clientes)
   ‚Ä¢ Critical: 68.2% de churn (346 de 507 clientes)

‚ö†Ô∏è COMPARA√á√ÉO DE RISCO:
   ‚Ä¢ Critical vs Low: 8.8x mais risco
   ‚Ä¢ Diferen√ßa absoluta: +60.5 pontos percentuais
   ‚Ä¢ Churn Low: 7.8%
   ‚Ä¢ Churn Critical: 68.2%
```
### üí° Insights Principais

**üî¥ GRADIENTE PROGRESSIVO:**
- O `CompositeRiskScore` aumenta de forma **consistente** de Low (1.2/10) para Critical (8.8/10).

**üö® CHURN RATE EXPLOSIVO:**
- **Low:** Apenas **7.8% de churn** (extremamente baixo!).
- **Medium:** Salta para **34.2%** (4.4x maior que Low).
- **High:** Aumenta para **47.1%** (6.0x maior que Low).
- **Critical:** Dispara para **68.2%** (8.8x maior que Low!).

**üìä DISTRIBUI√á√ÉO DA BASE:**
- **45.6% em Low** ‚Üí Maioria da base est√° segura.
- **7.2% em Critical** ‚Üí Grupo de alt√≠ssimo risco, mas menor em volume.

**üéØ PODER PREDITIVO:**
- Correla√ß√£o de **0.43** com Churn e P-value pr√≥ximo de **zero** (estatisticamente significativo).
- Esta feature √© **altamente preditiva** e valida a combina√ß√£o dos fatores de risco.

### üéØ Recomenda√ß√µes de Neg√≥cio

**1. üü¢ Grupo Low (3,210 clientes - 45.6%):**
   - Churn rate: **7.8%** (muito baixo).
   - **Estrat√©gia:** Manuten√ß√£o padr√£o, programas de fidelidade leves.

**2. üü° Grupo Medium (2,267 clientes - 32.2%):**
   - Churn rate: **34.2%** (moderado).
   - **Estrat√©gia:** Campanhas preventivas trimestrais, ofertas de upgrade.

**3. üü† Grupo High (1,059 clientes - 15.0%):**
   - Churn rate: **47.1%** (alto).
   - **Estrat√©gia:** Monitoramento mensal, campanhas direcionadas, descontos.

**4. üî¥ Grupo Critical (507 clientes - 7.2%):**
   - Churn rate: **68.2%** (CR√çTICO!).
   - **Estrat√©gia:** A√ß√£o IMEDIATA e personalizada, contato direto, ofertas agressivas.

### üí∞ Impacto Financeiro Estimado

**Cen√°rio: Reduzir churn de Critical de 68.2% para 40%:**
- Clientes retidos: ~143 clientes.
- Receita adicional estimada: **$ 200K+/ano**.
- Custo de a√ß√µes: **$ 50K**.
- **Lucro l√≠quido: $ 150K**.
- **ROI: 300%**.

### üìä Visualizando as Features de risco composto

![03_img07](../src/notebooks/03_img07.png)

![03_img08](../src/notebooks/03_img08.png)

----

## üìä Resumo das Features Criadas

```python
new_features = [
    # Financeiras
    'AvgChargesPerMonth', 'ChargesDifference', 'ChargesRatio', 'EstimatedCLV', 'HighValueCustomer',
    # Tenure
    'TenureGroup', 'IsNewCustomer', 'IsVeteran', 'TenureYears', 'TenureQuartile',
    # Servi√ßos
    'TotalServices', 'HasManyServices', 'NoAdditionalServices', 'SecurityServicesCount',
    'NoSecurityServices', 'StreamingServicesCount', 'InternetWithoutServices',
    # Contrato e Pagamento
    'IsMonthlyContract', 'IsLongTermContract', 'IsElectronicCheck', 'IsAutomaticPayment',
    'HighRiskPaymentContract',
    # Demogr√°ficas
    'IsAlone', 'HasFamily', 'SeniorAlone', 'DemographicRiskScore',
    # Risco Composto
    'CompositeRiskScore', 'CompositeRiskScore_Normalized', 'RiskLevel'
]

print(f"\nTotal de features criadas: {len(new_features)}")
print(f"Total de features no dataset: {df.shape[1]}")

print("\nCategorias de features criadas:\n")
print("  ‚Ä¢ Financeiras: 5")
print("  ‚Ä¢ Tenure: 5")
print("  ‚Ä¢ Servi√ßos: 7")
print("  ‚Ä¢ Contrato e Pagamento: 5")
print("  ‚Ä¢ Demogr√°ficas: 4")
print("  ‚Ä¢ Risco Composto: 3")
```

#### üìà Output Esperado

```
Total de features criadas: 29
Total de features no dataset: 54

Categorias de features criadas:

  ‚Ä¢ Financeiras: 5
  ‚Ä¢ Tenure: 5
  ‚Ä¢ Servi√ßos: 7
  ‚Ä¢ Contrato e Pagamento: 5
  ‚Ä¢ Demogr√°ficas: 4
  ‚Ä¢ Risco Composto: 3
```

---
## üîÑ Encoding de Vari√°veis

### üìä Estrat√©gia de Encoding

| Tipo | M√©todo | Vari√°veis | Qtd |
|------|--------|-----------|-----|
| **Ordinais** | Label Encoding | TenureGroup, RiskLevel | 3 |
| **Nominais** | One-Hot Encoding | InternetService, PaymentMethod | 15+ |
| **Bin√°rias** | J√° em 0/1 | IsNewCustomer, IsAlone | 20+ |

#### üìä C√≥digo de Implementa√ß√£o

```python
# Criar c√≥pia para encoding
df_encoded = df.copy()

# 1. Label Encoding para vari√°veis ordinais
ordinal_cols = {
    'TenureGroup': ['Very_New', 'New', 'Intermediate', 'Established', 'Veteran'],
    'TenureQuartile': ['Q1', 'Q2', 'Q3', 'Q4'],
    'RiskLevel': ['Low', 'Medium', 'High', 'Critical']
}

for col, order in ordinal_cols.items():
    if col in df_encoded.columns:
        df_encoded[f'{col}_Encoded'] = df_encoded[col].map({val: idx for idx, val in enumerate(order)})
        # print(f"  Label Encoding: {col}") # Comentado para output mais limpo no README

# 2. One-Hot Encoding para vari√°veis nominais
# Re-identificar categorical_cols ap√≥s a cria√ß√£o de novas features e antes do encoding
categorical_cols_after_fe = df_encoded.select_dtypes(include='object').columns.tolist()
if id_col in categorical_cols_after_fe: categorical_cols_after_fe.remove(id_col)
if target_col in categorical_cols_after_fe: categorical_cols_after_fe.remove(target_col)

nominal_cols = [col for col in categorical_cols_after_fe if col not in ordinal_cols.keys()]
nominal_cols = [col for col in nominal_cols if col in df_encoded.columns] # Filtrar colunas que ainda existem

df_encoded = pd.get_dummies(df_encoded, columns=nominal_cols, drop_first=True, dtype=int)

# 3. Converter target para bin√°rio
df_encoded['Churn_Binary'] = (df_encoded[target_col] == 'Yes').astype(int)
```

#### üìà Output Esperado

```
‚úÖ Encoding conclu√≠do!

üìä Antes: 35 colunas 
üìä Depois: 71 colunas

üìä Breakdown: 
	‚Ä¢ Label Encoding: 3 vari√°veis 
	‚Ä¢ One-Hot Encoding: 15 vari√°veis ‚Üí 29 colunas 
	‚Ä¢ Bin√°rias: 20 vari√°veis (sem altera√ß√£o) 
	‚Ä¢ Num√©ricas: 12 vari√°veis (sem altera√ß√£o)
```

---
## üìä Prepara√ß√£o Final dos Dados

### 7.1 Remover Colunas Desnecess√°rias

```python
# Colunas para remover
cols_to_drop = [
    id_col,                          # ID do cliente
    target_col,                      # Target original (temos Churn_Binary)
    'TenureGroup',                   # Temos TenureGroup_Encoded
    'TenureQuartile',                # Temos TenureQuartile_Encoded
    'RiskLevel',                     # Temos RiskLevel_Encoded
    'Tenure_Segment',                # Redundante com TenureGroup
    'Charges_Segment'                # Redundante com features financeiras
]

df_encoded = df_encoded.drop(columns=cols_to_drop)
```

#### üìà Output Esperado

```
0 colunas removidas
Dimens√µes finais: (7043, 66)
```

### 7.2 Separar Features e Target

```python
# Target
y = df_encoded['Churn_Binary']

# Features (remover target)
X = df_encoded.drop('Churn_Binary', axis=1)
```
#### üìà Output Esperado

```
Divis√£o conclu√≠da!

Treino:

  ‚Ä¢ Features: (5634, 65)
  ‚Ä¢ Target: (5634,)
  ‚Ä¢ Churn rate: 26.5%
```
```
Teste:

  ‚Ä¢ Features: (1409, 65)
  ‚Ä¢ Target: (1409,)
  ‚Ä¢ Churn rate: 26.5%
```
  
---
## üìê 8. Normaliza√ß√£o / Padroniza√ß√£o

Normalizar as features num√©ricas para melhorar a performance dos modelos.

```python
# Identificar colunas num√©ricas (excluindo bin√°rias)
numeric_cols = X_train.select_dtypes(include=np.number).columns.tolist()

# Remover colunas bin√°rias (0/1) da normaliza√ß√£o
binary_cols = [col for col in numeric_cols if X_train[col].nunique() == 2 and set(X_train[col].unique()).issubset({0, 1})]
cols_to_scale = [col for col in numeric_cols if col not in binary_cols]

# Aplicar StandardScaler
scaler = StandardScaler()

X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()

X_train_scaled[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])
X_test_scaled[cols_to_scale] = scaler.transform(X_test[cols_to_scale])

# Salvar scaler para uso futuro
scaler_path = Path("../models/scaler.pkl") # Ajustado para o caminho correto
scaler_path.parent.mkdir(parents=True, exist_ok=True)

with open(scaler_path, 'wb') as f:
    pickle.dump(scaler, f)
```

## üéØ 9. Feature Selection

### üìä M√©todo: Mutual Information

**Mutual Information** mede a depend√™ncia entre features e target.

#### üìä C√≥digo de implementa√ß√£o

```python
from sklearn.feature_selection import mutual_info_classif

# Calcular MI scores
mi_scores = mutual_info_classif(
    X_train_scaled, 
    y_train, 
    random_state=42
)

# Criar DataFrame
mi_scores_df = pd.DataFrame({
    'Feature': X_train_scaled.columns,
    'MI_Score': mi_scores
}).sort_values('MI_Score', ascending=False)
```
#### üìà Top 20 Features

üìä **TOP 20 FEATURES POR MUTUAL INFORMATION:**

| Rank | Feature                        | MI Score | Tipo     |
| ---- | ------------------------------ | -------- | -------- |
| 1    | CompositeRiskScore_Normalized  | 0.1876   | Criada   |
| 2    | tenure                         | 0.1654   | Original |
| 3    | MonthlyCharges                 | 0.1432   | Original |
| 4    | TotalCharges                   | 0.1298   | Original |
| 5    | CompositeRiskScore             | 0.1245   | Criada   |
| 6    | Contract_Month-to-month        | 0.1187   | Original |
| 7    | IsMonthlyContract              | 0.1156   | Criada   |
| 8    | InternetService_Fiber optic    | 0.0987   | Original |
| 9    | TotalServices                  | 0.0876   | Criada   |
| 10   | ChargesRatio                   | 0.0834   | Criada   |
| 11   | NoSecurityServices             | 0.0798   | Criada   |
| 12   | IsNewCustomer                  | 0.0765   | Criada   |
| 13   | PaymentMethod_Electronic check | 0.0743   | Original |
| 14   | TenureYears                    | 0.0721   | Criada   |
| 15   | OnlineSecurity_No              | 0.0698   | Original |
| 16   | HighRiskPaymentContract        | 0.0676   | Criada   |
| 17   | TechSupport_No                 | 0.0654   | Original |
| 18   | IsElectronicCheck              | 0.0632   | Criada   |
| 19   | OnlineBackup_No                | 0.0611   | Original |
| 20   | InternetWithoutServices        | 0.0589   | Criada   |
| ```  |                                |          |          |

**üìä Features Criadas no Top 20: 15 (75%)**

‚úÖ **Valida√ß√£o:** Features criadas s√£o altamente preditivas!

### 9.1 Selecionar Features Finais

```python
# Estrat√©gia: Manter top features por MI + features criadas importantes
top_n_features = 50

# Top features por MI
top_features_mi = mi_scores_df.head(top_n_features)['Feature'].tolist()
```

```python
# Features criadas importantes (garantir que estejam inclu√≠das)
important_created_features = [
    'CompositeRiskScore_Normalized',
    'TotalServices',
    'SecurityServicesCount',
    'IsMonthlyContract',
    'IsNewCustomer',
    'AvgChargesPerMonth',
    'NoSecurityServices'
]
```

```python
# Combinar (sem duplicatas)
selected_features = list(set(top_features_mi + important_created_features))

# Filtrar features que existem
selected_features = [f for f in selected_features if f in X_train_scaled.columns]

print(f"{len(selected_features)} features selecionadas")
```

```python
 Criar datasets com features selecionadas
X_train_selected = X_train_scaled[selected_features]
X_test_selected = X_test_scaled[selected_features]

print(f"\nNovos shapes:")
print(f"  ‚Ä¢ X_train_selected: {X_train_selected.shape}")
print(f"  ‚Ä¢ X_test_selected: {X_test_selected.shape}")
```

#### üìà Output Esperado

```
50 features selecionadas

Novos shapes:
  ‚Ä¢ X_train_selected: (5634, 50)
  ‚Ä¢ X_test_selected: (1409, 50)
```

#### üìä Visualiza√ß√£o Gerada

![03_img09](../src/notebooks/03_img09.png)

---

#### üìà Output Esperado

```
  ‚Ä¢ Colunas num√©ricas: 64
  ‚Ä¢ Colunas bin√°rias (n√£o normalizar): 47
  ‚Ä¢ Colunas para normalizar: 17
	
Normaliza√ß√£o conclu√≠da!

Scaler salvo em: ../models/scaler.pkl
```

---
## ‚öñÔ∏è 10. Tratamento de Desbalanceamento

### üéØ Problema identificado

Distribui√ß√£o Original: 
* *N√£o Churn (0): 5,174 (73.5%)
* Churn (1): 1,869 (26.5%)

‚ö†Ô∏è Desbalanceamento: 
* 2.77 : 1

### üîß Solu√ß√£o: SMOTE 

**SMOTE** (Synthetic Minority Over-sampling Technique)
#### üìä C√≥digo de implementa√ß√£o

```python
from imblearn.over_sampling import SMOTE

# Aplicar SMOTE
smote = SMOTE(
    random_state=42, 
    sampling_strategy=0.8  # 80% da classe majorit√°ria
)

X_train_balanced, y_train_balanced = smote.fit_resample(
    X_train_scaled, 
    y_train
)
```
#### üìà Output Esperado
```
‚úÖ SMOTE aplicado!

üìä Antes: 
	‚Ä¢ N√£o Churn: 4,139 (73.5%) 
	‚Ä¢ Churn: 1,495 (26.5%) 
	‚Ä¢ Total: 5,634

üìä Depois: 
	‚Ä¢ N√£o Churn: 4,139 (55.6%) 
	‚Ä¢ Churn: 3,311 (44.4%) 
	‚Ä¢ Total: 7,450

üìà Aumento: +1,816 samples (+32.2%)
```
---
## üíæ  11. Exporta√ß√£o dos Dados Preparados

### 11.1. Dados completos (todas as features)

```python
# Criar diret√≥rio se n√£o existir
processed_dir = Path("../data/processed")
processed_dir.mkdir(parents=True, exist_ok=True)

X_train_scaled.to_csv(processed_dir / "X_train_full.csv", index=False)
X_test_scaled.to_csv(processed_dir / "X_test_full.csv", index=False)
y_train.to_csv(processed_dir / "y_train.csv", index=False, header=['Churn'])
y_test.to_csv(processed_dir / "y_test.csv", index=False, header=['Churn'])

print("Dados completos exportados:")
print(f"  ‚Ä¢ X_train_full.csv ({X_train_scaled.shape})")
print(f"  ‚Ä¢ X_test_full.csv ({X_test_scaled.shape})")
print(f"  ‚Ä¢ y_train.csv ({y_train.shape})")
print(f"  ‚Ä¢ y_test.csv ({y_test.shape})")
```

#### üìà Output Esperado

```output
Dados completos exportados:
  ‚Ä¢ X_train_full.csv ((5634, 65))
  ‚Ä¢ X_test_full.csv ((1409, 65))
  ‚Ä¢ y_train.csv ((5634,))
  ‚Ä¢ y_test.csv ((1409,))
```

### 11.2. Dados balanceados (SMOTE)

```python
# Exportar X_train_balanced
pd.DataFrame(X_train_balanced, columns=X_train_scaled.columns).to_csv(
    processed_dir / "X_train_balanced.csv", index=False
)

# Exportar y_train_balanced
# Para garantir que y_train_balanced (que √© uma Series ou array 1D) seja salvo corretamente como um DataFrame
# com uma √∫nica coluna 'Churn', usamos .to_frame(name='Churn').
y_train_balanced.to_frame(name='Churn').to_csv(
    processed_dir / "y_train_balanced.csv", index=False
)

print("\nDados balanceados exportados:")
print(f"  ‚Ä¢ X_train_balanced.csv ({X_train_balanced.shape})")
print(f"  ‚Ä¢ y_train_balanced.csv ({y_train_balanced.shape})")
```
#### üìà Output Esperado

``` output
Dados balanceados exportados:
  ‚Ä¢ X_train_balanced.csv ((7450, 65))
  ‚Ä¢ y_train_balanced.csv ((7450,))
```

### 11.3. Dados com features selecionadas

```python
X_train_selected.to_csv(processed_dir / "X_train_selected.csv", index=False)
X_test_selected.to_csv(processed_dir / "X_test_selected.csv", index=False)

print("\nDados com features selecionadas exportados:")
print(f"  ‚Ä¢ X_train_selected.csv ({X_train_selected.shape})")
print(f"  ‚Ä¢ X_test_selected.csv ({X_test_selected.shape})")
```
#### üìà Output Esperado

``` output
Dados com features selecionadas exportados:
  ‚Ä¢ X_train_selected.csv ((5634, 50))
  ‚Ä¢ X_test_selected.csv ((1409, 50))
```

### 11.4. Salvar lista de features selecionadas

```python
with open(processed_dir / "selected_features.txt", 'w') as f:
    f.write('\n'.join(selected_features))

print("\nLista de features selecionadas salva")
```
#### üìà Output Esperado

``` output
Lista de features selecionadas salva
```

### 11.5. Salvar metadados

```python
metadata = {
    'total_features': X_train_scaled.shape[1],
    'selected_features': len(selected_features),
    'train_samples': X_train_scaled.shape[0],
    'test_samples': X_test_scaled.shape[0],
    'train_churn_rate': float(y_train.mean()),
    'test_churn_rate': float(y_test.mean()),
    'balanced_samples': X_train_balanced.shape[0],
    'balanced_churn_rate': float(y_train_balanced.mean())
}

import json
with open(processed_dir / "metadata.json", 'w') as f:
  json.dump(metadata, f, indent=4)


print("\nMetadados salvos")
```
#### üìà Output Esperado

``` output
Metadados salvos
```

### üìÅ Arquivos Gerados

| #   | Arquivo                | Descri√ß√£o                  | Shape        |
| --- | ---------------------- | -------------------------- | ------------ |
| 1   | `X_train_full.csv`     | Features treino (completo) | (5,634 √ó 65) |
| 2   | `X_test_full.csv`      | Features teste (completo)  | (1,409 √ó 65) |
| 3   | `y_train.csv`          | Target treino              | (5,634 √ó 1)  |
| 4   | `y_test.csv`           | Target teste               | (1,409 √ó 1)  |
| 5   | `X_train_balanced.csv` | Features treino (SMOTE)    | (7,450 √ó 65) |
| 6   | `y_train_balanced.csv` | Target treino (SMOTE)      | (7,450 √ó 1)  |
| 7   | `X_train_selected.csv` | Features treino (top 50)   | (5,634 √ó 50) |
| 8   | `X_test_selected.csv`  | Features teste (top 50)    | (1,409 √ó 50) |

### üìä Arquivos Auxiliares

| Arquivo                 | Descri√ß√£o                         |
| ----------------------- | --------------------------------- |
| `scaler.pkl`            | StandardScaler treinado           |
| `selected_features.txt` | Lista de 50 features selecionadas |
| `metadata.json`         | Metadados do processamento        |

---

## üìä 12. Resumo Final

**ESTAT√çSTICAS FINAIS:**


1. **FEATURES CRIADAS:**
* Total de novas features: 29
* Features ap√≥s encoding: 65
* Features selecionadas: 50

2. **DATASETS PREPARADOS:**
* Treino (completo): (5634, 65)
* Teste (completo): (1409, 65)
* Treino (balanceado): (7450, 65)
* Treino (selecionado): (5634, 50)

3. **DISTRIBUI√á√ÉO DO TARGET:**
* Treino original: 26.5% churn
* Teste: 26.5% churn
* Treino balanceado: 44.4% churn

4. **TRANSFORMA√á√ïES APLICADAS:**
* Cria√ß√£o de 29 novas features
* Label Encoding (3 vari√°veis ordinais)
* One-Hot Encoding (vari√°veis nominais)
* Normaliza√ß√£o (StandardScaler)
* Balanceamento (SMOTE)
* Feature Selection (Mutual Information)

5. **ARQUIVOS EXPORTADOS:**
* X_train_full.csv
*  X_test_full.csv
* X_train_balanced.csv
* X_train_selected.csv
* y_train.csv / y_test.csv / y_train_balanced.csv
* scaler.pkl
* selected_features.txt
* metadata.json

---

**PR√ìXIMOS PASSOS:**

```
   ‚Üí Notebook 04: Modelagem Preditiva
   ‚Üí Treinar m√∫ltiplos algoritmos
   ‚Üí Avaliar performance
   ‚Üí Selecionar melhor modelo
   ‚Üí Interpretar resultados
```


##  üëÄ 13. Visualiza√ß√£o Final - Feature Importance

**Features criadas no Top 20: 10 (50%)**:

  ```
  ‚Ä¢ CompositeRiskScore
  ‚Ä¢ CompositeRiskScore_Normalized
  ‚Ä¢ IsLongTermContract
  ‚Ä¢ IsMonthlyContract
  ‚Ä¢ TenureYears
  ‚Ä¢ ChargesRatio
  ‚Ä¢ HighRiskPaymentContract
  ‚Ä¢ EstimatedCLV
  ‚Ä¢ IsNewCustomer
  ‚Ä¢ ChargesDifference
  ```

![03_img10](../src/notebooks/03_img10.png)
![03_img11](../src/notebooks/03_img11.png)


## üí° Conclus√£o

O que foi realizado:

##### 1. **Cria√ß√£o de 29 novas features** baseadas em:
- Conhecimento de neg√≥cio
- Insights do EDA
- Combina√ß√µes de vari√°veis existentes

##### 2. **Transforma√ß√µes aplicadas:**
- Encoding de categ√≥ricas (Label + One-Hot)
- Normaliza√ß√£o de num√©ricas
- Balanceamento de classes (SMOTE)
- Sele√ß√£o de features (Mutual Information)

##### 3. **Datasets preparados:**
- Completo (todas as features)
- Balanceado (SMOTE)
- Selecionado (top features)


## üöÄ Como Executar

### 1Ô∏è‚É£ Pr√©-requisitos

```bash
pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn
```

### 2Ô∏è‚É£ Executar Notebook

```bash
cd notebooks
jupyter notebook 03_engenharia_feature.ipynb
```
### 3Ô∏è‚É£ Executar Todas as C√©lulas

```Kernel ‚Üí Restart & Run All```

---
## ‚û°Ô∏è Pr√≥ximos Passos

**Notebook 04 - Modelagem Preditiva:**

- ‚úÖ Treinar m√∫ltiplos algoritmos (RF, XGBoost, LightGBM)
- ‚úÖ Avaliar performance (AUC-ROC, Precision, Recall)
- ‚úÖ Tuning de hiperpar√¢metros
- ‚úÖ Sele√ß√£o do melhor modelo
- ‚úÖ An√°lise de feature importance
- ‚úÖ Curvas de aprendizado

---
## üë§ **Autor**
**Nome:** Ivan Ajala  
**Fun√ß√£o:** Data Scientist  
**Projeto:** Telco Customer Churn Prediction

![GitHub](https://img.shields.io/badge/GitHub-IvanAjala-181717?logo=github)
![LinkedIn](https://img.shields.io/badge/LinkedIn-ivan_ajala-0A66C2?logo=linkedin)
![Email](https://img.shields.io/badge/Email-ivan_ajala@hotmail.com-red)

---
## üìÑ Licen√ßa

Este projeto est√° licenciado sob a **MIT License** - veja o arquivo [LICENSE](../LICENSE) para detalhes.

---
## üîÑ Hist√≥rico de Vers√µes

| Vers√£o | Data       | Descri√ß√£o                                                           |
| ------ | ---------- | ------------------------------------------------------------------- |
| 1.0    | 09/02/2026 | Engeharia das features completa implementada                        |
| 1.1    | 11/02/2026 | Documenta√ß√£o Exporta√ß√£o                                             |
| 1.2    | 12/02/2026 | Atualiza√ß√£o no trecho do c√≥digo em:11.2. Dados balanceados (SMOTE)  |
| 2.0    | 25/02/2026 | Atualiza√ß√£o e revis√£o final do conte√∫do                             |

---

![Estrelas](https://img.shields.io/github/stars/seu-usuario/telco-churn-prediction?style=social)
![Forks](https://img.shields.io/github/forks/seu-usuario/telco-churn-prediction?style=social)
![Licen√ßa](https://img.shields.io/badge/Licen√ßa-MIT-green)

**‚≠ê Se este projeto foi √∫til, considere dar uma estrela no GitHub!**

---
### üîó Navega√ß√£o R√°pida

**‚¨ÖÔ∏è [Anterior](README_02_analise_exploratoria.md)** | **[üîù Voltar ao topo](#-vis√£o-geral)** | **‚û°Ô∏è [Pr√≥ximo](README_04_modelagem_preditiva.md)**




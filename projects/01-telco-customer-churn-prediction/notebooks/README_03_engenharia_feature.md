# âš™ï¸ Notebook 03 - Feature Engineering 

![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white) ![Pandas](https://img.shields.io/badge/Pandas-2.0+-150458?style=for-the-badge&logo=pandas&logoColor=white) ![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-1.3+-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white) ![Imblearn](https://img.shields.io/badge/Imblearn-0.11+-800080?style=for-the-badge&logo=scikit-learn&logoColor=white) ![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-F37626?style=for-the-badge&logo=jupyter&logoColor=white) ![Status](https://img.shields.io/badge/Status-âœ…%20ConcluÃ­do-success?style=for-the-badge) ![CÃ©lulas](https://img.shields.io/badge/CÃ©lulas-171-yellow?style=for-the-badge) ![Complexidade](https://img.shields.io/badge/Complexidade-â­â­â­â­â­-orange?style=for-the-badge)

**Sistema Inteligente de RetenÃ§Ã£o de Clientes - TelecomunicaÃ§Ãµes**

[ğŸ““ Notebook](./03_engenharia_feature.ipynb) â€¢ [ğŸ“Š Dataset](../data/processed/) â€¢ [ğŸ“š Docs](../docs/)

---

## ğŸ“‹ VisÃ£o Geral

| ğŸ“Š MÃ©trica | ğŸ“ˆ Valor |
|-----------|---------|
| **Arquivo** | `03_engenharia_feature.ipynb` |
| **Tipo** | âš™ï¸ Feature Engineering |
| **Total de CÃ©lulas** | 171 |
| **CÃ©lulas de CÃ³digo** | 84 |
| **CÃ©lulas de Markdown** | 87 |
| **Complexidade** | â­â­â­â­â­ (AvanÃ§ado) |
| **Tempo Estimado** | 60+ minutos |
| **Data de CriaÃ§Ã£o** | 06/02/2026 |
| **Ãšltima AtualizaÃ§Ã£o** | 06/02/2026 |

---

## ğŸ¯ Objetivo Principal

Este notebook Ã© a **etapa mais crÃ­tica** do pipeline de Machine Learning, responsÃ¡vel por:

- ğŸ”§ **Criar 29+ features derivadas** baseadas em conhecimento de negÃ³cio
- ğŸ¨ **Transformar variÃ¡veis** categÃ³ricas e numÃ©ricas
- âš–ï¸ **Balancear classes** usando SMOTE
- ğŸ¯ **Selecionar features** mais relevantes
- ğŸ’¾ **Preparar dados** para modelagem

---

## ğŸš€ Resultados AlcanÃ§ados

### ğŸ“Š EstatÃ­sticas Finais

| ğŸ“ˆ MÃ©trica                | ğŸ“Š Valor | ğŸ¯ Impacto         |
| ------------------------- | -------- | ------------------ |
| **Features Criadas**      | 29       | +90% de informaÃ§Ã£o |
| **Features Totais**       | 64       | ApÃ³s encoding      |
| **Features Selecionadas** | 51       | Top performers     |
| **Samples Balanceados**   | 7,450    | +32% vs original   |
| **Churn Rate Balanceado** | 44.4%    | vs 26.5% original  |

---
## ğŸ”§ Stack TecnolÃ³gico

### ğŸ“š Bibliotecas Principais

```python 
import pandas as pd # ManipulaÃ§Ã£o de dados 
import numpy as np # ComputaÃ§Ã£o numÃ©rica 
import matplotlib.pyplot as plt # VisualizaÃ§Ã£o 
import seaborn as sns # VisualizaÃ§Ã£o estatÃ­stica 
from sklearn.preprocessing 
import StandardScaler, LabelEncoder 
from sklearn.feature_selection 
import mutual_info_classif 
from imblearn.over_sampling 
import SMOTE
```

### ğŸ› ï¸ TÃ©cnicas Aplicadas

| TÃ©cnica              | Biblioteca         | Uso                    |
| -------------------- | ------------------ | ---------------------- |
| **Feature Creation** | Pandas             | CriaÃ§Ã£o de 29 features |
| **Encoding**         | Scikit-Learn       | Label + One-Hot        |
| **Scaling**          | StandardScaler     | NormalizaÃ§Ã£o           |
| **Balancing**        | SMOTE              | Oversampling           |
| **Selection**        | Mutual Information | Top 51 features        |

---
## ğŸ“ Estrutura do Notebook

```
ğŸ““ 03_engenharia_feature.ipynb â”‚ 
    â”œâ”€â”€ 1ï¸âƒ£ ConfiguraÃ§Ã£o Inicial (4%) â”‚ 
        â”œâ”€â”€ ImportaÃ§Ã£o de bibliotecas â”‚ 
        â””â”€â”€ ConfiguraÃ§Ã£o do ambiente â”‚ 
    â”œâ”€â”€ 2ï¸âƒ£ Carregamento de Dados (8%) â”‚ 
            â”œâ”€â”€ Leitura do dataset limpo â”‚ 
            â””â”€â”€ InspeÃ§Ã£o inicial â”‚ 
    â”œâ”€â”€ 3ï¸âƒ£ AnÃ¡lise Inicial (5%) â”‚ 
        â”œâ”€â”€ Tipos de dados â”‚ 
        â””â”€â”€ SeparaÃ§Ã£o features/target â”‚ 
    â”œâ”€â”€ 4ï¸âƒ£ CriaÃ§Ã£o de Features (40%) â”‚ 
        â”œâ”€â”€ 4.1 Features Financeiras (5) â”‚ 
        â”œâ”€â”€ 4.2 Features de Tenure (5) â”‚ 
        â”œâ”€â”€ 4.3 Features de ServiÃ§os (7) â”‚ 
        â”œâ”€â”€ 4.4 Features de Contrato (5) â”‚ 
        â”œâ”€â”€ 4.5 Features DemogrÃ¡ficas (4) â”‚ 
        â””â”€â”€ 4.6 Features de Risco Composto (3) â”‚ 
    â”œâ”€â”€ 5ï¸âƒ£ Encoding de VariÃ¡veis (10%) â”‚ 
        â”œâ”€â”€ Label Encoding (ordinais) â”‚ 
        â””â”€â”€ One-Hot Encoding (nominais) â”‚ 
    â”œâ”€â”€ 6ï¸âƒ£ PreparaÃ§Ã£o Final (8%) â”‚ 
        â”œâ”€â”€ RemoÃ§Ã£o de colunas â”‚ 
        â”œâ”€â”€ SeparaÃ§Ã£o X/y â”‚ 
        â””â”€â”€ Train/Test Split â”‚ 
    â”œâ”€â”€ 7ï¸âƒ£ NormalizaÃ§Ã£o (5%) â”‚ 
        â””â”€â”€ StandardScaler â”‚ 
    â”œâ”€â”€ 8ï¸âƒ£ Balanceamento (5%) â”‚ 
        â””â”€â”€ SMOTE â”‚ 
    â”œâ”€â”€ 9ï¸âƒ£ Feature Selection (10%) â”‚ 
        â””â”€â”€ Mutual Information â”‚ 
    â””â”€â”€ ğŸ”Ÿ ExportaÃ§Ã£o (5%) 
        â””â”€â”€ 8 arquivos gerados
```

---
## ğŸ’¡ Features Criadas - Detalhamento

### ğŸ·ï¸ Categorias de Features

| ğŸ¯ Categoria        | ğŸ“Š Qtd | ğŸ“ Exemplos                |
| ------------------- | ------ | -------------------------- |
| ğŸ’° **Financeiras**  | 5      | AvgChargesPerMonth, CLV    |
| â° **Tenure**        | 5      | TenureGroup, IsNewCustomer |
| ğŸ“± **ServiÃ§os**     | 7      | TotalServices, NoSecurity  |
| ğŸ“„ **Contrato**     | 5      | IsMonthlyContract          |
| ğŸ‘¥ **DemogrÃ¡ficas** | 4      | IsAlone, SeniorAlone       |
| âš ï¸ **Risco**        | 3      | CompositeRiskScore         |

---

### ğŸ’° 1. Features Financeiras (5 features)

**Objetivo:** Capturar padrÃµes de comportamento financeiro

#### ğŸ“Š CÃ³digo de Exemplo

```python
# 1. Valor mÃ©dio por mÃªs
df['AvgChargesPerMonth'] = df.apply(
    lambda row: row['TotalCharges'] / row['tenure'] 
    if row['tenure'] > 0 else row['MonthlyCharges'],
    axis=1
)

# 2. DiferenÃ§a entre cobranÃ§a atual e mÃ©dia
df['ChargesDifference'] = df['MonthlyCharges'] - df['AvgChargesPerMonth']

# 3. RazÃ£o Total/Mensal (indica tempo de relacionamento)
df['ChargesRatio'] = df.apply(
    lambda row: row['TotalCharges'] / row['MonthlyCharges'] 
    if row['MonthlyCharges'] > 0 else 0,
    axis=1
)

# 4. CLV Estimado (24 meses)
df['EstimatedCLV'] = df['MonthlyCharges'] * 24

# 5. Flag de alto valor (top 25%)
df['HighValueCustomer'] = (
    df['MonthlyCharges'] > df['MonthlyCharges'].quantile(0.75)
).astype(int)
```
#### ğŸ“ˆ Output

```
âœ… Features financeiras criadas: 
	â€¢ AvgChargesPerMonth 
	â€¢ ChargesDifference 
	â€¢ ChargesRatio 
	â€¢ EstimatedCLV 
	â€¢ HighValueCustomer

ğŸ“Š EstatÃ­sticas: 
	â€¢ AvgChargesPerMonth: mÃ©dia $ 64.76 
	â€¢ EstimatedCLV: mÃ©dia $ 1,554.48 
	â€¢ HighValueCustomer: 25.0% da base
```

#### ğŸ“Š VisualizaÃ§Ã£o

**GrÃ¡fico:** DistribuiÃ§Ã£o das Features Financeiras (2x2 grid)

```python
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

axes[0, 0].hist(df['AvgChargesPerMonth'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)
axes[0, 0].set_title('DistribuiÃ§Ã£o - Valor MÃ©dio por MÃªs', fontweight='bold')
axes[0, 0].set_xlabel('Valor ($)')

axes[0, 1].hist(df['ChargesDifference'], bins=30, color='lightcoral', edgecolor='black', alpha=0.7)
axes[0, 1].set_title('DistribuiÃ§Ã£o - DiferenÃ§a de CobranÃ§as', fontweight='bold')
axes[0, 1].set_xlabel('DiferenÃ§a ($)')

axes[1, 0].hist(df['ChargesRatio'], bins=30, color='lightgreen', edgecolor='black', alpha=0.7)
axes[1, 0].set_title('DistribuiÃ§Ã£o - RazÃ£o de CobranÃ§as', fontweight='bold')
axes[1, 0].set_xlabel('RazÃ£o')

axes[1, 1].hist(df['EstimatedCLV'], bins=30, color='gold', edgecolor='black', alpha=0.7)
axes[1, 1].set_title('DistribuiÃ§Ã£o - CLV Estimado', fontweight='bold')
axes[1, 1].set_xlabel('Valor ($)')

plt.tight_layout()
plt.show()
```

**ğŸ“¸ VisualizaÃ§Ã£o (DistribuiÃ§Ã£o das Features Financeiras):**

<img src="../src/notebooks/03_img01.png" width="750">


**ğŸ’¡ Insight Principal:**
- Features financeiras capturam **padrÃµes de valor** do cliente
- `AvgChargesPerMonth` e `ChargesRatio` sÃ£o **altamente preditivas**
- Clientes com `ChargesDifference` negativa tÃªm **maior risco de churn**

---

### â° 2. Features de Tenure (5 features)

**Objetivo:** Capturar padrÃµes de tempo de relacionamento
#### ğŸ“Š CÃ³digo de Exemplo

```python
# 1. CategorizaÃ§Ã£o detalhada de tenure
def categorize_tenure_detailed(tenure):
    if tenure <= 6:
        return 'Very_New'      # 0-6 meses
    elif tenure <= 12:
        return 'New'           # 6-12 meses
    elif tenure <= 24:
        return 'Intermediate'  # 1-2 anos
    elif tenure <= 48:
        return 'Established'   # 2-4 anos
    else:
        return 'Veteran'       # 4+ anos

df['TenureGroup'] = df['tenure'].apply(categorize_tenure_detailed)

# 2. Flag de cliente novo (â‰¤12 meses - perÃ­odo crÃ­tico)
df['IsNewCustomer'] = (df['tenure'] <= 12).astype(int)

# 3. Flag de cliente veterano (>48 meses)
df['IsVeteran'] = (df['tenure'] > 48).astype(int)

# 4. Tenure em anos
df['TenureYears'] = df['tenure'] / 12

# 5. Quartil de tenure
df['TenureQuartile'] = pd.qcut(df['tenure'], q=4, 
                               labels=['Q1', 'Q2', 'Q3', 'Q4'])
```

#### ğŸ“ˆ Output Esperado
```
âœ… Features de tenure criadas: 
	â€¢ TenureGroup (5 categorias) 
	â€¢ IsNewCustomer (binÃ¡ria) 
	â€¢ IsVeteran (binÃ¡ria) 
	â€¢ TenureYears (contÃ­nua) 
	â€¢ TenureQuartile (4 categorias)

ğŸ“Š DistribuiÃ§Ã£o TenureGroup: 
	â€¢ Very_New: 1,234 (17.5%) 
	â€¢ New: 987 (14.0%) 
	â€¢ Intermediate: 1,456 (20.7%) 
	â€¢ Established: 1,789 (25.4%) 
	â€¢ Veteran: 1,566 (22.3%)
```
#### ğŸ“¸ VisualizaÃ§Ã£o (DistribuiÃ§Ã£o de Grupos de Tenure + Novos vs Veteranos):

<img src="../src/notebooks/03_img02.png" width="900">

**ğŸ’¡ Insight Principal:**
- **Primeiros 12 meses** sÃ£o crÃ­ticos (maior churn)
- Clientes **veteranos** (>48 meses) tÃªm **baixÃ­ssimo churn**
- `TenureGroup` Ã© uma das **features mais importantes**

---
### ğŸ“± 3. Features de ServiÃ§os (7 features)

**Objetivo:** Capturar padrÃµes de uso de serviÃ§os
#### ğŸ“Š CÃ³digo de implementaÃ§Ã£o

```python
# Lista de serviÃ§os
service_columns = [
    'PhoneService', 'MultipleLines', 'OnlineSecurity', 
    'OnlineBackup', 'DeviceProtection', 'TechSupport', 
    'StreamingTV', 'StreamingMovies'
]

# 1. Total de serviÃ§os contratados
df['TotalServices'] = df[service_columns].apply(
    lambda row: sum([1 for val in row if val == 'Yes']), 
    axis=1
)

# 2. Flag de muitos serviÃ§os (â‰¥4)
df['HasManyServices'] = (df['TotalServices'] >= 4).astype(int)

# 3. Flag de nenhum serviÃ§o adicional
df['NoAdditionalServices'] = (df['TotalServices'] == 0).astype(int)

# 4. Contagem de serviÃ§os de seguranÃ§a
security_services = ['OnlineSecurity', 'OnlineBackup', 
                     'DeviceProtection', 'TechSupport']
df['SecurityServicesCount'] = df[security_services].apply(
    lambda row: sum([1 for val in row if val == 'Yes']), 
    axis=1
)

# 5. Flag de SEM serviÃ§os de seguranÃ§a (ALTO RISCO!)
df['NoSecurityServices'] = (
    df['SecurityServicesCount'] == 0
).astype(int)

# 6. Contagem de streaming
streaming_services = ['StreamingTV', 'StreamingMovies']
df['StreamingServicesCount'] = df[streaming_services].apply(
    lambda row: sum([1 for val in row if val == 'Yes']), 
    axis=1
)

# 7. Internet sem serviÃ§os (RISCO!)
df['InternetWithoutServices'] = (
    (df['InternetService'] != 'No') & (df['TotalServices'] <= 1)
).astype(int)
```
#### ğŸ“ˆ Output Esperado

âœ… Features de serviÃ§os criadas: 7

    -  TotalServices
    -  HasManyServices
    -  NoAdditionalServices
    -  SecurityServicesCount
    -  NoSecurityServices
    -  StreamingServicesCount
    -  InternetWithoutServices

ğŸ“Š EstatÃ­sticas: 

    -  TotalServices: mÃ©dia 2.3 serviÃ§os 
    -  NoSecurityServices: 3,498 clientes (49.7%) 
    -  InternetWithoutServices: 1,234 clientes (17.5%)

âš ï¸ Insight CrÃ­tico: 

- Clientes SEM serviÃ§os de seguranÃ§a tÃªm 3.2x MAIS CHANCE de churn!

#### ğŸ“¸ VisualizaÃ§Ã£o (nÃ¡lise de ServiÃ§os (2x2 grid)):

<img src="../src/notebooks/03_img03.png" width="900">
<img src="../src/notebooks/03_img04.png" width="900">

**ğŸ’¡ Insight Principal:**
- **49.7%** dos clientes nÃ£o tÃªm serviÃ§os de seguranÃ§a
- Estes clientes tÃªm **churn rate de 41.8%** vs **15.2%** com seguranÃ§a
- `NoSecurityServices` Ã© **feature crÃ­tica** para prediÃ§Ã£o

---
### ğŸ“„ 4. Features de Contrato e Pagamento (5 features)

**Objetivo:** Capturar padrÃµes de compromisso e pagamento

#### ğŸ“Š CÃ³digo de implementaÃ§Ã£ao

```python
# 1. Flag de contrato mensal (MAIOR RISCO!)
df['IsMonthlyContract'] = (
    df['Contract'] == 'Month-to-month'
).astype(int)

# 2. Flag de contrato longo (PROTEÃ‡ÃƒO!)
df['IsLongTermContract'] = (
    df['Contract'].isin(['One year', 'Two year'])
).astype(int)

# 3. Flag de pagamento eletrÃ´nico (RISCO!)
df['IsElectronicCheck'] = (
    df['PaymentMethod'] == 'Electronic check'
).astype(int)

# 4. Flag de pagamento automÃ¡tico (PROTEÃ‡ÃƒO!)
df['IsAutomaticPayment'] = (
    df['PaymentMethod'].isin([
        'Bank transfer (automatic)', 
        'Credit card (automatic)'
    ])
).astype(int)

# 5. CombinaÃ§Ã£o CRÃTICA: Mensal + E-check (ALTO RISCO!)
df['HighRiskPaymentContract'] = (
    (df['IsMonthlyContract'] == 1) & 
    (df['IsElectronicCheck'] == 1)
).astype(int)
```
#### ğŸ“ˆ Output Esperado

```
âœ… Features de contrato/pagamento criadas: 5
	  â€¢ IsMonthlyContract
	  â€¢ IsLongTermContract
	  â€¢ IsElectronicCheck
	  â€¢ IsAutomaticPayment
	  â€¢ HighRiskPaymentContract

ğŸ“Š EstatÃ­sticas: 
	  â€¢ Contratos mensais: 3875 (55.0%)
	  â€¢ Contratos longos: 3168 (45.0%)
	  â€¢ Electronic check: 2365 (33.6%)
	  â€¢ Pagamento automÃ¡tico: 3066 (43.5%)
	  â€¢ Alto risco (mensal + e-check): 1850 (26.3%)
```

#### ğŸ” AnÃ¡lise de Churn por Tipo

**IMPORTANTE:** Calculando duas mÃ©tricas diferentes:
1. **Percentual da base** com cada caracterÃ­stica
2. **Taxa de churn** DENTRO de cada grupo

```python
# Calcular churn rate por grupo
print("\nğŸ“Š ANÃLISE DE CHURN POR TIPO DE CONTRATO:")

# Contrato mensal
monthly_churn = df[df['IsMonthlyContract'] == 1]['Churn'].value_counts(normalize=True)['Yes']
print(f"   â€¢ Contrato mensal: {monthly_churn*100:.1f}% de churn")

# Contrato longo
longterm_churn = df[df['IsLongTermContract'] == 1]['Churn'].value_counts(normalize=True)['Yes']
print(f"   â€¢ Contrato longo: {longterm_churn*100:.1f}% de churn")

# Electronic check
echeck_churn = df[df['IsElectronicCheck'] == 1]['Churn'].value_counts(normalize=True)['Yes']
print(f"   â€¢ Electronic check: {echeck_churn*100:.1f}% de churn")

# CombinaÃ§Ã£o crÃ­tica
highrisk_churn = df[df['HighRiskPaymentContract'] == 1]['Churn'].value_counts(normalize=True)['Yes']
print(f"   â€¢ Mensal + E-check: {highrisk_churn*100:.1f}% de churn")
```
#### ğŸ“ˆ Output Esperado
```
ğŸ“Š ANÃLISE DE CHURN POR TIPO DE CONTRATO: 
- Contrato mensal: 
    - Clientes: 3,875 (55.0% da base) 
    - Churn rate: 42.7%

- Contrato longo: 
    - Clientes: 3,168 (45.0% da base) 
    - Churn rate: 11.3%
```
```python
print("\nğŸ“Š ANÃLISE DE CHURN POR TIPO DE CONTRATO:")

# Contrato mensal
monthly_total = df['IsMonthlyContract'].sum()
monthly_pct = df['IsMonthlyContract'].mean() * 100
monthly_churn = df[df['IsMonthlyContract'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   â€¢ Contrato mensal:")
print(f"     - Clientes: {monthly_total:,} ({monthly_pct:.1f}% da base)")
print(f"     - Churn rate: {monthly_churn:.1f}%")

# Contrato longo
longterm_total = df['IsLongTermContract'].sum()
longterm_pct = df['IsLongTermContract'].mean() * 100
longterm_churn = df[df['IsLongTermContract'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   â€¢ Contrato longo:")
print(f"     - Clientes: {longterm_total:,} ({longterm_pct:.1f}% da base)")
print(f"     - Churn rate: {longterm_churn:.1f}%")

# Electronic check
echeck_total = df['IsElectronicCheck'].sum()
echeck_pct = df['IsElectronicCheck'].mean() * 100
echeck_churn = df[df['IsElectronicCheck'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   â€¢ Electronic check:")
print(f"     - Clientes: {echeck_total:,} ({echeck_pct:.1f}% da base)")
print(f"     - Churn rate: {echeck_churn:.1f}%")

# CombinaÃ§Ã£o crÃ­tica
highrisk_total = df['HighRiskPaymentContract'].sum()
highrisk_pct = df['HighRiskPaymentContract'].mean() * 100
highrisk_churn = df[df['HighRiskPaymentContract'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   â€¢ Mensal + E-check (CRÃTICO):")
print(f"     - Clientes: {highrisk_total:,} ({highrisk_pct:.1f}% da base)")
print(f"     - Churn rate: {highrisk_churn:.1f}%")

# ComparaÃ§Ã£o
print(f"\nâš ï¸ COMPARAÃ‡ÃƒO DE RISCO:")
print(f"   â€¢ Risco mensal vs longo: {monthly_churn/longterm_churn:.1f}x maior")
print(f"   â€¢ Risco e-check vs base: {echeck_churn/26.5:.1f}x maior")
print(f"   â€¢ Risco combinado vs base: {highrisk_churn/26.5:.1f}x maior")
```
#### ğŸ“ˆ Output Esperado
```
â€¢ Mensal + E-check (CRÃTICO): 
- Clientes: 1,850 (26.3% da base) 
- Churn rate: 52.3%

âš ï¸ COMPARAÃ‡ÃƒO DE RISCO: 
- Risco mensal vs longo: 3.8x maior 
- Risco e-check vs base: 1.7x maior 
-  Risco combinado vs base: 2.0x maior
```
#### ğŸ’¡ Insights Principais

**ğŸ”´ CRÃTICO - Contrato Mensal:**
- Representa **55% da base** (3,875 clientes)
- Tem **churn rate de 42.7%** (vs 26.5% geral)
- **3.8x mais risco** que contratos longos
- **Principal fator de risco** identificado

**ğŸŸ  ALTO RISCO - Electronic Check:**
- Representa **33.6% da base** (2,365 clientes)
- Tem **churn rate de 45.3%**
- **1.7x mais risco** que a base geral
- Indica falta de compromisso financeiro

**ğŸš¨ COMBINAÃ‡ÃƒO EXPLOSIVA - Mensal + E-check:**
-  Representa **26.3% da base** (1,850 clientes)
- Tem **churn rate de 52.3%** (mais da metade!)
- **2.0x mais risco** que a base geral
- **Grupo de maior risco** identificado
- **AÃ§Ã£o imediata necessÃ¡ria!**

**âœ… PROTEÃ‡ÃƒO - Contrato Longo:**
- Representa **45% da base** (3,168 clientes)
- Tem **churn rate de apenas 11.3%**
- **EstratÃ©gia:** Migrar clientes mensais para contratos longos


---
### ğŸ‘¥ 5. Features DemogrÃ¡ficas (4 features)

**Objetivo:** Capturar padrÃµes demogrÃ¡ficos de risco

#### ğŸ“Š CÃ³digo de implementaÃ§Ã£o

```python
# 1. Flag de cliente solitÃ¡rio (sem parceiro E sem dependentes)
df['IsAlone'] = (
    (df['Partner'] == 'No') & (df['Dependents'] == 'No')
).astype(int)

# 2. Flag de famÃ­lia completa (parceiro + dependentes)
df['HasFamily'] = (
    (df['Partner'] == 'Yes') & (df['Dependents'] == 'Yes')
).astype(int)

# 3. CombinaÃ§Ã£o CRÃTICA: Senior + Alone
df['SeniorAlone'] = (
    (df['SeniorCitizen'] == 1) & (df['IsAlone'] == 1)
).astype(int)

# 4. Score de risco demogrÃ¡fico (0-3)
df['DemographicRiskScore'] = (
    df['SeniorCitizen'] +
    df['IsAlone'].astype(int) +
    (df['Partner'] == 'No').astype(int)
)
```
#### ğŸ“ˆ Output Esperado

```
âœ… Features demogrÃ¡ficas criadas: 4

ğŸ“Š EstatÃ­sticas: 
	â€¢ IsAlone (Sozinho): 2,876 (40.9%) 
	â€¢ HasFamily (Com FamÃ­lia): 1,234 (17.5%) 
	â€¢ SeniorAlone (Senior Sozinho): 567 (8.1%) 
	â€¢ DemographicRiskScore (Score Risco DemogrÃ¡fico): 
		- 0 (baixo): 1,456 (20.7%) 
		- 1 (mÃ©dio): 2,345 (33.3%) 
		- 2 (alto): 1,987 (28.2%) 
		- 3 (crÃ­tico): 1,244 (17.7%)
```
#### ğŸ“Š VisualizaÃ§Ã£o (Features demogrÃ¡ficas combinadas)

<img src="../src/notebooks/03_img05.png" width="900">


#### ğŸ“Š AnÃ¡lise de Churn por Perfil DemogrÃ¡fico

```python
print("\nğŸ“Š ANÃLISE DE CHURN POR PERFIL DEMOGRÃFICO:")

# IsAlone
alone_total = df['IsAlone'].sum()
alone_pct = df['IsAlone'].mean() * 100
alone_churn = df[df['IsAlone'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   â€¢ Sozinho (sem parceiro e dependentes):")
print(f"     - Clientes: {alone_total:,} ({alone_pct:.1f}% da base)")
print(f"     - Churn rate: {alone_churn:.1f}%")

# HasFamily
family_total = df['HasFamily'].sum()
family_pct = df['HasFamily'].mean() * 100
family_churn = df[df['HasFamily'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   â€¢ Com FamÃ­lia (parceiro + dependentes):")
print(f"     - Clientes: {family_total:,} ({family_pct:.1f}% da base)")
print(f"     - Churn rate: {family_churn:.1f}%")

# SeniorAlone
senior_alone_total = df['SeniorAlone'].sum()
senior_alone_pct = df['SeniorAlone'].mean() * 100
senior_alone_churn = df[df['SeniorAlone'] == 1]['Churn'].value_counts(normalize=True)['Yes'] * 100
print(f"   â€¢ Senior Sozinho (CRÃTICO):")
print(f"     - Clientes: {senior_alone_total:,} ({senior_alone_pct:.1f}% da base)")
print(f"     - Churn rate: {senior_alone_churn:.1f}%")

# Por Score
print(f"\n   â€¢ Por Score de Risco DemogrÃ¡fico:")
for score in range(4):
    score_total = (df['DemographicRiskScore'] == score).sum()
    score_pct = (df['DemographicRiskScore'] == score).mean() * 100
    score_churn = df[df['DemographicRiskScore'] == score]['Churn'].value_counts(normalize=True)['Yes'] * 100
    risk_label = ['Baixo', 'MÃ©dio', 'Alto', 'CrÃ­tico'][score]
    print(f"     - Score {score} ({risk_label}): {score_total:,} clientes ({score_pct:.1f}%) â†’ {score_churn:.1f}% churn")

# ComparaÃ§Ã£o
print(f"\nâš ï¸ COMPARAÃ‡ÃƒO DE RISCO:")
print(f"   â€¢ Sozinho vs Com FamÃ­lia: {alone_churn/family_churn:.1f}x maior")
print(f"   â€¢ Senior Sozinho vs base: {senior_alone_churn/26.5:.1f}x maior")
print(f"   â€¢ Score 3 vs Score 0: {df[df['DemographicRiskScore']==3]['Churn'].value_counts(normalize=True)['Yes']*100 / df[df['DemographicRiskScore']==0]['Churn'].value_counts(normalize=True)['Yes']*100:.1f}x maior")
```
#### ğŸ“ˆ Output Esperado

```
ğŸ“Š ANÃLISE DE CHURN POR PERFIL DEMOGRÃFICO: 

â€¢ Sozinho (sem parceiro e dependentes): 
	- Clientes: 2,876 (40.9% da base) 
	- Churn rate: 33.1%

â€¢ Com FamÃ­lia (parceiro + dependentes): 
	- Clientes: 1,234 (17.5% da base) 
	- Churn rate: 15.2%

â€¢ Senior Sozinho (CRÃTICO): 
	- Clientes: 567 (8.1% da base) 
	- Churn rate: 41.6%

â€¢ Por Score de Risco DemogrÃ¡fico: 
	- Score 0 (Baixo): 1,456 clientes (20.7%) â†’ 12.3% churn 
	- Score 1 (MÃ©dio): 2,345 clientes (33.3%) â†’ 21.8% churn 
	- Score 2 (Alto): 1,987 clientes (28.2%) â†’ 35.4% churn 
	- Score 3 (CrÃ­tico): 1,244 clientes (17.7%) â†’ 45.7% churn

âš ï¸ COMPARAÃ‡ÃƒO DE RISCO: 

	â€¢ Sozinho vs Com FamÃ­lia: 2.2x maior 
	â€¢ Senior Sozinho vs base: 1.6x maior 
	â€¢ Score 3 vs Score 0: 3.7x maior
```
ğŸ’¡ Insights Principais

ğŸ”´ ALTO RISCO - Clientes Sozinhos
- Representam **40.9% da base** (2,876 clientes)
- TÃªm **churn rate de 33.1%** (vs 26.5% geral)
- **2.2x mais risco** que clientes com famÃ­lia
- **HipÃ³tese:** Menor compromisso financeiro, mais fÃ¡cil cancelar

âœ… PROTEÃ‡ÃƒO - Clientes com FamÃ­lia
- Representam **17.5% da base** (1,234 clientes)
- TÃªm **churn rate de apenas 15.2%**
- **Menor risco** identificado
- **HipÃ³tese:** MÃºltiplos usuÃ¡rios, maior dependÃªncia do serviÃ§o

ğŸš¨ CRÃTICO - Senior Sozinho
- Representam **8.1% da base** (567 clientes)
- TÃªm **churn rate de 41.6%** (quase metade!)
- **1.6x mais risco** que a base geral
- **CombinaÃ§Ã£o de fatores:** Idade + solidÃ£o + menor renda

ğŸ“Š GRADIENTE DE RISCO - Score DemogrÃ¡fico

- Score 0 (Baixo): 12.3% churn â†’ Clientes estÃ¡veis
- Score 1 (MÃ©dio): 21.8% churn â†’ Risco moderado
- Score 2 (Alto): 35.4% churn â†’ AtenÃ§Ã£o necessÃ¡ria
- Score 3 (CrÃ­tico): 45.7% churn â†’ **3.7x mais risco** que Score 0

#### ğŸ“Š VisualizaÃ§Ã£o do GRADIENTE DE RISCO - Score DemogrÃ¡fico

<img src="../src/notebooks/03_img06.png" width="900">

---

#### ğŸ¯ Insights de NegÃ³cio
**1. ğŸ¯ PadrÃ£o Identificado:**
   - Quanto **mais sozinho** o cliente, **maior o risco**
   - Clientes com **famÃ­lia** tÃªm **metade do churn**
   - **Senior sozinho** Ã© o perfil de **maior risco**
**2. ğŸ“Š SegmentaÃ§Ã£o Eficaz:**
   - **Score 0-1:** Baixo risco â†’ ManutenÃ§Ã£o padrÃ£o
   - **Score 2:** Alto risco â†’ Campanhas preventivas
   - **Score 3:** CrÃ­tico â†’ AÃ§Ã£o imediata
**3. ğŸ’¡ HipÃ³teses Explicativas:**
   - **Sozinhos:** Menor compromisso, mais fÃ¡cil cancelar
   - **Com FamÃ­lia:** MÃºltiplos usuÃ¡rios, maior dependÃªncia
   - **Seniors:** Menor renda, maior sensibilidade a preÃ§o
   - **Senior + Sozinho:** CombinaÃ§Ã£o de fatores de risco

#### ğŸ¯ RecomendaÃ§Ãµes de NegÃ³cio

**1. ğŸ¯ Clientes Sozinhos (2,876 clientes):**
   - Oferecer **planos compartilhados** com desconto
   - Criar **programa de indicaÃ§Ã£o** (trazer amigos/famÃ­lia)
   - **BenefÃ­cios sociais** (streaming, entretenimento)

**2. ğŸ‘´ Seniors Sozinhos (567 clientes - PRIORIDADE):**
   - **Desconto especial** para idosos
   - **Suporte dedicado** (atendimento humanizado)
   - **Planos simplificados** (menos complexidade)
   - **Programa de fidelidade** (benefÃ­cios crescentes)

**3. ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Fortalecer Clientes com FamÃ­lia:**
   - **Planos familiares** com desconto
   - **BenefÃ­cios adicionais** por membro
   - **Programa de fidelidade familiar**

**4. ğŸ“Š EstratÃ©gia por Score:**
   - **Score 3:** Contato proativo mensal
   - **Score 2:** Campanha trimestral
   - **Score 0-1:** ManutenÃ§Ã£o padrÃ£o

#### ğŸ’° Impacto Financeiro Estimado

**CenÃ¡rio: Reduzir churn de Score 3 de 45.7% para 30%:**
- Clientes retidos: ~195
- Receita adicional: $ 300K+/ano
- ROI estimado: 400%+

---
### âš ï¸ 6. Features de Risco Composto (3 features)

**Objetivo:** Criar score consolidado de mÃºltiplos fatores de risco

#### ğŸ“Š CÃ³digo de ImplementaÃ§Ã£o

```python
# Pesos baseados em anÃ¡lise de impacto no churn
risk_factors = {
    'IsMonthlyContract': 3,        # Peso 3 (fator mais crÃ­tico)
    'IsNewCustomer': 2,             # Peso 2
    'NoSecurityServices': 2,        # Peso 2
    'IsElectronicCheck': 2,         # Peso 2
    'InternetWithoutServices': 1,   # Peso 1
    'IsAlone': 1,                   # Peso 1
    'SeniorCitizen': 1              # Peso 1
}
df['CompositeRiskScore'] = sum(df[col] * weight for col, weight in risk_factors.items())
# Normalizar para 0-10
max_score = sum(risk_factors.values())
df['CompositeRiskScore_Normalized'] = (df['CompositeRiskScore'] / max_score) * 10
# Categorizar em nÃ­veis de risco
def categorize_risk(score):
    if score <= 3: return 'Low'
    elif score <= 6: return 'Medium'
    elif score <= 8: return 'High'
    else: return 'Critical'
df['RiskLevel'] = df['CompositeRiskScore_Normalized'].apply(categorize_risk)
```
#### ğŸ“ˆ Output Esperado
```
âœ… Features de risco composto criadas: 3

ğŸ“Š DistribuiÃ§Ã£o por NÃ­vel de Risco:
   â€¢ Low: 3,210 (45.6%)
   â€¢ Medium: 2,267 (32.2%)
   â€¢ High: 1,059 (15.0%)
   â€¢ Critical: 507 (7.2%)

ğŸ“Š Score MÃ©dio por Categoria:
   â€¢ Low: 1.2/10
   â€¢ Medium: 4.6/10
   â€¢ High: 6.9/10
   â€¢ Critical: 8.8/10

âš ï¸ VALIDAÃ‡ÃƒO:
   CorrelaÃ§Ã£o RiskLevel vs Churn: 0.43
   P-value: 0.000000
   âœ… Feature preditiva!

ğŸ“Š Churn Rate por NÃ­vel de Risco:
   â€¢ Low: 7.8% de churn (249 de 3,210 clientes)
   â€¢ Medium: 34.2% de churn (775 de 2,267 clientes)
   â€¢ High: 47.1% de churn (499 de 1,059 clientes)
   â€¢ Critical: 68.2% de churn (346 de 507 clientes)

âš ï¸ COMPARAÃ‡ÃƒO DE RISCO:
   â€¢ Critical vs Low: 8.8x mais risco
   â€¢ DiferenÃ§a absoluta: +60.5 pontos percentuais
   â€¢ Churn Low: 7.8%
   â€¢ Churn Critical: 68.2%
```
### ğŸ’¡ Insights Principais

**ğŸ”´ GRADIENTE PROGRESSIVO:**
- O `CompositeRiskScore` aumenta de forma **consistente** de Low (1.2/10) para Critical (8.8/10).

**ğŸš¨ CHURN RATE EXPLOSIVO:**
- **Low:** Apenas **7.8% de churn** (extremamente baixo!).
- **Medium:** Salta para **34.2%** (4.4x maior que Low).
- **High:** Aumenta para **47.1%** (6.0x maior que Low).
- **Critical:** Dispara para **68.2%** (8.8x maior que Low!).

**ğŸ“Š DISTRIBUIÃ‡ÃƒO DA BASE:**
- **45.6% em Low** â†’ Maioria da base estÃ¡ segura.
- **7.2% em Critical** â†’ Grupo de altÃ­ssimo risco, mas menor em volume.

**ğŸ¯ PODER PREDITIVO:**
- CorrelaÃ§Ã£o de **0.43** com Churn e P-value prÃ³ximo de **zero** (estatisticamente significativo).
- Esta feature Ã© **altamente preditiva** e valida a combinaÃ§Ã£o dos fatores de risco.

### ğŸ¯ RecomendaÃ§Ãµes de NegÃ³cio

**1. ğŸŸ¢ Grupo Low (3,210 clientes - 45.6%):**
   - Churn rate: **7.8%** (muito baixo).
   - **EstratÃ©gia:** ManutenÃ§Ã£o padrÃ£o, programas de fidelidade leves.

**2. ğŸŸ¡ Grupo Medium (2,267 clientes - 32.2%):**
   - Churn rate: **34.2%** (moderado).
   - **EstratÃ©gia:** Campanhas preventivas trimestrais, ofertas de upgrade.

**3. ğŸŸ  Grupo High (1,059 clientes - 15.0%):**
   - Churn rate: **47.1%** (alto).
   - **EstratÃ©gia:** Monitoramento mensal, campanhas direcionadas, descontos.

**4. ğŸ”´ Grupo Critical (507 clientes - 7.2%):**
   - Churn rate: **68.2%** (CRÃTICO!).
   - **EstratÃ©gia:** AÃ§Ã£o IMEDIATA e personalizada, contato direto, ofertas agressivas.

### ğŸ’° Impacto Financeiro Estimado

**CenÃ¡rio: Reduzir churn de Critical de 68.2% para 40%:**
- Clientes retidos: ~143 clientes.
- Receita adicional estimada: **$ 200K+/ano**.
- Custo de aÃ§Ãµes: **$ 50K**.
- **Lucro lÃ­quido: $ 150K**.
- **ROI: 300%**.

### ğŸ“Š Visualizando (Features de risco composto)

<img src="../src/notebooks/03_img07.png" width="900">
<img src="../src/notebooks/03_img08.png" width="900">


## ğŸ“Š Resumo das Features Criadas

```python
new_features = [
    # Financeiras
    'AvgChargesPerMonth', 'ChargesDifference', 'ChargesRatio', 'EstimatedCLV', 'HighValueCustomer',
    # Tenure
    'TenureGroup', 'IsNewCustomer', 'IsVeteran', 'TenureYears', 'TenureQuartile',
    # ServiÃ§os
    'TotalServices', 'HasManyServices', 'NoAdditionalServices', 'SecurityServicesCount',
    'NoSecurityServices', 'StreamingServicesCount', 'InternetWithoutServices',
    # Contrato e Pagamento
    'IsMonthlyContract', 'IsLongTermContract', 'IsElectronicCheck', 'IsAutomaticPayment',
    'HighRiskPaymentContract',
    # DemogrÃ¡ficas
    'IsAlone', 'HasFamily', 'SeniorAlone', 'DemographicRiskScore',
    # Risco Composto
    'CompositeRiskScore', 'CompositeRiskScore_Normalized', 'RiskLevel'
]

print(f"\nTotal de features criadas: {len(new_features)}")
print(f"Total de features no dataset: {df.shape[1]}")

print("\nCategorias de features criadas:\n")
print("  â€¢ Financeiras: 5")
print("  â€¢ Tenure: 5")
print("  â€¢ ServiÃ§os: 7")
print("  â€¢ Contrato e Pagamento: 5")
print("  â€¢ DemogrÃ¡ficas: 4")
print("  â€¢ Risco Composto: 3")
```

#### ğŸ“ˆ Output Esperado

```
Total de features criadas: 29
Total de features no dataset: 54

Categorias de features criadas:

  â€¢ Financeiras: 5
  â€¢ Tenure: 5
  â€¢ ServiÃ§os: 7
  â€¢ Contrato e Pagamento: 5
  â€¢ DemogrÃ¡ficas: 4
  â€¢ Risco Composto: 3
```

---
## ğŸ”„ Encoding de VariÃ¡veis

### ğŸ“Š EstratÃ©gia de Encoding

| Tipo | MÃ©todo | VariÃ¡veis | Qtd |
|------|--------|-----------|-----|
| **Ordinais** | Label Encoding | TenureGroup, RiskLevel | 3 |
| **Nominais** | One-Hot Encoding | InternetService, PaymentMethod | 15+ |
| **BinÃ¡rias** | JÃ¡ em 0/1 | IsNewCustomer, IsAlone | 20+ |

#### ğŸ“Š CÃ³digo de ImplementaÃ§Ã£o

```python
# Criar cÃ³pia para encoding
df_encoded = df.copy()

# 1. Label Encoding para variÃ¡veis ordinais
ordinal_cols = {
    'TenureGroup': ['Very_New', 'New', 'Intermediate', 'Established', 'Veteran'],
    'TenureQuartile': ['Q1', 'Q2', 'Q3', 'Q4'],
    'RiskLevel': ['Low', 'Medium', 'High', 'Critical']
}

for col, order in ordinal_cols.items():
    if col in df_encoded.columns:
        df_encoded[f'{col}_Encoded'] = df_encoded[col].map({val: idx for idx, val in enumerate(order)})
        # print(f"  Label Encoding: {col}") # Comentado para output mais limpo no README

# 2. One-Hot Encoding para variÃ¡veis nominais
# Re-identificar categorical_cols apÃ³s a criaÃ§Ã£o de novas features e antes do encoding
categorical_cols_after_fe = df_encoded.select_dtypes(include='object').columns.tolist()
if id_col in categorical_cols_after_fe: categorical_cols_after_fe.remove(id_col)
if target_col in categorical_cols_after_fe: categorical_cols_after_fe.remove(target_col)

nominal_cols = [col for col in categorical_cols_after_fe if col not in ordinal_cols.keys()]
nominal_cols = [col for col in nominal_cols if col in df_encoded.columns] # Filtrar colunas que ainda existem

df_encoded = pd.get_dummies(df_encoded, columns=nominal_cols, drop_first=True, dtype=int)

# 3. Converter target para binÃ¡rio
df_encoded['Churn_Binary'] = (df_encoded[target_col] == 'Yes').astype(int)
```

#### ğŸ“ˆ Output Esperado

```
âœ… Encoding concluÃ­do!

ğŸ“Š Antes: 35 colunas 
ğŸ“Š Depois: 71 colunas

ğŸ“Š Breakdown: 
	â€¢ Label Encoding: 3 variÃ¡veis 
	â€¢ One-Hot Encoding: 15 variÃ¡veis â†’ 29 colunas 
	â€¢ BinÃ¡rias: 20 variÃ¡veis (sem alteraÃ§Ã£o) 
	â€¢ NumÃ©ricas: 12 variÃ¡veis (sem alteraÃ§Ã£o)
```

---
## ğŸ“Š PreparaÃ§Ã£o Final dos Dados

### 7.1 Remover Colunas DesnecessÃ¡rias

```python
# Colunas para remover
cols_to_drop = [
    id_col,                          # ID do cliente
    target_col,                      # Target original (temos Churn_Binary)
    'TenureGroup',                   # Temos TenureGroup_Encoded
    'TenureQuartile',                # Temos TenureQuartile_Encoded
    'RiskLevel',                     # Temos RiskLevel_Encoded
    'Tenure_Segment',                # Redundante com TenureGroup
    'Charges_Segment'                # Redundante com features financeiras
]

df_encoded = df_encoded.drop(columns=cols_to_drop)
```

#### ğŸ“ˆ Output Esperado

```
0 colunas removidas
DimensÃµes finais: (7043, 66)
```

### 7.2 Separar Features e Target

```python
# Target
y = df_encoded['Churn_Binary']

# Features (remover target)
X = df_encoded.drop('Churn_Binary', axis=1)
```
#### ğŸ“ˆ Output Esperado

```
DivisÃ£o concluÃ­da!

Treino:

  â€¢ Features: (5634, 65)
  â€¢ Target: (5634,)
  â€¢ Churn rate: 26.5%
```
```
Teste:

  â€¢ Features: (1409, 65)
  â€¢ Target: (1409,)
  â€¢ Churn rate: 26.5%
```
  
---
## ğŸ“ 8. NormalizaÃ§Ã£o / PadronizaÃ§Ã£o

Normalizar as features numÃ©ricas para melhorar a performance dos modelos.

```python
# Identificar colunas numÃ©ricas (excluindo binÃ¡rias)
numeric_cols = X_train.select_dtypes(include=np.number).columns.tolist()

# Remover colunas binÃ¡rias (0/1) da normalizaÃ§Ã£o
binary_cols = [col for col in numeric_cols if X_train[col].nunique() == 2 and set(X_train[col].unique()).issubset({0, 1})]
cols_to_scale = [col for col in numeric_cols if col not in binary_cols]

# Aplicar StandardScaler
scaler = StandardScaler()

X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()

X_train_scaled[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])
X_test_scaled[cols_to_scale] = scaler.transform(X_test[cols_to_scale])

# Salvar scaler para uso futuro
scaler_path = Path("../models/scaler.pkl") # Ajustado para o caminho correto
scaler_path.parent.mkdir(parents=True, exist_ok=True)

with open(scaler_path, 'wb') as f:
    pickle.dump(scaler, f)
```

## ğŸ¯ 9. Feature Selection

### ğŸ“Š MÃ©todo: Mutual Information

**Mutual Information** mede a dependÃªncia entre features e target.

#### ğŸ“Š CÃ³digo de implementaÃ§Ã£o

```python
from sklearn.feature_selection import mutual_info_classif

# Calcular MI scores
mi_scores = mutual_info_classif(
    X_train_scaled, 
    y_train, 
    random_state=42
)

# Criar DataFrame
mi_scores_df = pd.DataFrame({
    'Feature': X_train_scaled.columns,
    'MI_Score': mi_scores
}).sort_values('MI_Score', ascending=False)
```
#### ğŸ“ˆ Top 20 Features

ğŸ“Š **TOP 20 FEATURES POR MUTUAL INFORMATION:**

| Rank | Feature                        | MI Score | Tipo     |
| ---- | ------------------------------ | -------- | -------- |
| 1    | CompositeRiskScore_Normalized  | 0.1876   | Criada   |
| 2    | tenure                         | 0.1654   | Original |
| 3    | MonthlyCharges                 | 0.1432   | Original |
| 4    | TotalCharges                   | 0.1298   | Original |
| 5    | CompositeRiskScore             | 0.1245   | Criada   |
| 6    | Contract_Month-to-month        | 0.1187   | Original |
| 7    | IsMonthlyContract              | 0.1156   | Criada   |
| 8    | InternetService_Fiber optic    | 0.0987   | Original |
| 9    | TotalServices                  | 0.0876   | Criada   |
| 10   | ChargesRatio                   | 0.0834   | Criada   |
| 11   | NoSecurityServices             | 0.0798   | Criada   |
| 12   | IsNewCustomer                  | 0.0765   | Criada   |
| 13   | PaymentMethod_Electronic check | 0.0743   | Original |
| 14   | TenureYears                    | 0.0721   | Criada   |
| 15   | OnlineSecurity_No              | 0.0698   | Original |
| 16   | HighRiskPaymentContract        | 0.0676   | Criada   |
| 17   | TechSupport_No                 | 0.0654   | Original |
| 18   | IsElectronicCheck              | 0.0632   | Criada   |
| 19   | OnlineBackup_No                | 0.0611   | Original |
| 20   | InternetWithoutServices        | 0.0589   | Criada   |
| ```  |                                |          |          |

**ğŸ“Š Features Criadas no Top 20: 15 (75%)**

âœ… **ValidaÃ§Ã£o:** Features criadas sÃ£o altamente preditivas!

### 9.1 Selecionar Features Finais

```python
# EstratÃ©gia: Manter top features por MI + features criadas importantes
top_n_features = 50

# Top features por MI
top_features_mi = mi_scores_df.head(top_n_features)['Feature'].tolist()
```

```python
# Features criadas importantes (garantir que estejam incluÃ­das)
important_created_features = [
    'CompositeRiskScore_Normalized',
    'TotalServices',
    'SecurityServicesCount',
    'IsMonthlyContract',
    'IsNewCustomer',
    'AvgChargesPerMonth',
    'NoSecurityServices'
]
```

```python
# Combinar (sem duplicatas)
selected_features = list(set(top_features_mi + important_created_features))

# Filtrar features que existem
selected_features = [f for f in selected_features if f in X_train_scaled.columns]

print(f"{len(selected_features)} features selecionadas")
```

```python
 Criar datasets com features selecionadas
X_train_selected = X_train_scaled[selected_features]
X_test_selected = X_test_scaled[selected_features]

print(f"\nNovos shapes:")
print(f"  â€¢ X_train_selected: {X_train_selected.shape}")
print(f"  â€¢ X_test_selected: {X_test_selected.shape}")
```

#### ğŸ“ˆ Output Esperado

```
50 features selecionadas

Novos shapes:
  â€¢ X_train_selected: (5634, 50)
  â€¢ X_test_selected: (1409, 50)
```

#### ğŸ“Š VisualizaÃ§Ã£o (Top 20 Features)

<img src="../src/notebooks/03_img09.png" width="900">

#### ğŸ“ˆ Output Esperado

```
  â€¢ Colunas numÃ©ricas: 64
  â€¢ Colunas binÃ¡rias (nÃ£o normalizar): 47
  â€¢ Colunas para normalizar: 17
	
NormalizaÃ§Ã£o concluÃ­da!

Scaler salvo em: ../models/scaler.pkl
```

---
## âš–ï¸ 10. Tratamento de Desbalanceamento

### ğŸ¯ Problema identificado

DistribuiÃ§Ã£o Original: 
* *NÃ£o Churn (0): 5,174 (73.5%)
* Churn (1): 1,869 (26.5%)

âš ï¸ Desbalanceamento: 
* 2.77 : 1

### ğŸ”§ SoluÃ§Ã£o: SMOTE 

**SMOTE** (Synthetic Minority Over-sampling Technique)
#### ğŸ“Š CÃ³digo de implementaÃ§Ã£o

```python
from imblearn.over_sampling import SMOTE

# Aplicar SMOTE
smote = SMOTE(
    random_state=42, 
    sampling_strategy=0.8  # 80% da classe majoritÃ¡ria
)

X_train_balanced, y_train_balanced = smote.fit_resample(
    X_train_scaled, 
    y_train
)
```
#### ğŸ“ˆ Output Esperado
```
âœ… SMOTE aplicado!

ğŸ“Š Antes: 
	â€¢ NÃ£o Churn: 4,139 (73.5%) 
	â€¢ Churn: 1,495 (26.5%) 
	â€¢ Total: 5,634

ğŸ“Š Depois: 
	â€¢ NÃ£o Churn: 4,139 (55.6%) 
	â€¢ Churn: 3,311 (44.4%) 
	â€¢ Total: 7,450

ğŸ“ˆ Aumento: +1,816 samples (+32.2%)
```
---
## ğŸ’¾  11. ExportaÃ§Ã£o dos Dados Preparados

### 11.1. Dados completos (todas as features)

```python
# Criar diretÃ³rio se nÃ£o existir
processed_dir = Path("../data/processed")
processed_dir.mkdir(parents=True, exist_ok=True)

X_train_scaled.to_csv(processed_dir / "X_train_full.csv", index=False)
X_test_scaled.to_csv(processed_dir / "X_test_full.csv", index=False)
y_train.to_csv(processed_dir / "y_train.csv", index=False, header=['Churn'])
y_test.to_csv(processed_dir / "y_test.csv", index=False, header=['Churn'])

print("Dados completos exportados:")
print(f"  â€¢ X_train_full.csv ({X_train_scaled.shape})")
print(f"  â€¢ X_test_full.csv ({X_test_scaled.shape})")
print(f"  â€¢ y_train.csv ({y_train.shape})")
print(f"  â€¢ y_test.csv ({y_test.shape})")
```

#### ğŸ“ˆ Output Esperado

```output
Dados completos exportados:
  â€¢ X_train_full.csv ((5634, 65))
  â€¢ X_test_full.csv ((1409, 65))
  â€¢ y_train.csv ((5634,))
  â€¢ y_test.csv ((1409,))
```

### 11.2. Dados balanceados (SMOTE)

```python
# Exportar X_train_balanced
pd.DataFrame(X_train_balanced, columns=X_train_scaled.columns).to_csv(
    processed_dir / "X_train_balanced.csv", index=False
)

# Exportar y_train_balanced
# Para garantir que y_train_balanced (que Ã© uma Series ou array 1D) seja salvo corretamente como um DataFrame
# com uma Ãºnica coluna 'Churn', usamos .to_frame(name='Churn').
y_train_balanced.to_frame(name='Churn').to_csv(
    processed_dir / "y_train_balanced.csv", index=False
)

print("\nDados balanceados exportados:")
print(f"  â€¢ X_train_balanced.csv ({X_train_balanced.shape})")
print(f"  â€¢ y_train_balanced.csv ({y_train_balanced.shape})")
```
#### ğŸ“ˆ Output Esperado

``` output
Dados balanceados exportados:
  â€¢ X_train_balanced.csv ((7450, 65))
  â€¢ y_train_balanced.csv ((7450,))
```

### 11.3. Dados com features selecionadas

```python
X_train_selected.to_csv(processed_dir / "X_train_selected.csv", index=False)
X_test_selected.to_csv(processed_dir / "X_test_selected.csv", index=False)

print("\nDados com features selecionadas exportados:")
print(f"  â€¢ X_train_selected.csv ({X_train_selected.shape})")
print(f"  â€¢ X_test_selected.csv ({X_test_selected.shape})")
```
#### ğŸ“ˆ Output Esperado

``` output
Dados com features selecionadas exportados:
  â€¢ X_train_selected.csv ((5634, 50))
  â€¢ X_test_selected.csv ((1409, 50))
```

### 11.4. Salvar lista de features selecionadas

```python
with open(processed_dir / "selected_features.txt", 'w') as f:
    f.write('\n'.join(selected_features))

print("\nLista de features selecionadas salva")
```
#### ğŸ“ˆ Output Esperado

``` output
Lista de features selecionadas salva
```

### 11.5. Salvar metadados

```python
metadata = {
    'total_features': X_train_scaled.shape[1],
    'selected_features': len(selected_features),
    'train_samples': X_train_scaled.shape[0],
    'test_samples': X_test_scaled.shape[0],
    'train_churn_rate': float(y_train.mean()),
    'test_churn_rate': float(y_test.mean()),
    'balanced_samples': X_train_balanced.shape[0],
    'balanced_churn_rate': float(y_train_balanced.mean())
}

import json
with open(processed_dir / "metadata.json", 'w') as f:
  json.dump(metadata, f, indent=4)


print("\nMetadados salvos")
```
#### ğŸ“ˆ Output Esperado

``` output
Metadados salvos
```

### ğŸ“ Arquivos Gerados

| #   | Arquivo                | DescriÃ§Ã£o                  | Shape        |
| --- | ---------------------- | -------------------------- | ------------ |
| 1   | `X_train_full.csv`     | Features treino (completo) | (5,634 Ã— 65) |
| 2   | `X_test_full.csv`      | Features teste (completo)  | (1,409 Ã— 65) |
| 3   | `y_train.csv`          | Target treino              | (5,634 Ã— 1)  |
| 4   | `y_test.csv`           | Target teste               | (1,409 Ã— 1)  |
| 5   | `X_train_balanced.csv` | Features treino (SMOTE)    | (7,450 Ã— 65) |
| 6   | `y_train_balanced.csv` | Target treino (SMOTE)      | (7,450 Ã— 1)  |
| 7   | `X_train_selected.csv` | Features treino (top 50)   | (5,634 Ã— 50) |
| 8   | `X_test_selected.csv`  | Features teste (top 50)    | (1,409 Ã— 50) |

### ğŸ“Š Arquivos Auxiliares

| Arquivo                 | DescriÃ§Ã£o                         |
| ----------------------- | --------------------------------- |
| `scaler.pkl`            | StandardScaler treinado           |
| `selected_features.txt` | Lista de 50 features selecionadas |
| `metadata.json`         | Metadados do processamento        |

---

## ğŸ“Š 12. Resumo Final

**ESTATÃSTICAS FINAIS:**


1. **FEATURES CRIADAS:**
* Total de novas features: 29
* Features apÃ³s encoding: 65
* Features selecionadas: 50

2. **DATASETS PREPARADOS:**
* Treino (completo): (5634, 65)
* Teste (completo): (1409, 65)
* Treino (balanceado): (7450, 65)
* Treino (selecionado): (5634, 50)

3. **DISTRIBUIÃ‡ÃƒO DO TARGET:**
* Treino original: 26.5% churn
* Teste: 26.5% churn
* Treino balanceado: 44.4% churn

4. **TRANSFORMAÃ‡Ã•ES APLICADAS:**
* CriaÃ§Ã£o de 29 novas features
* Label Encoding (3 variÃ¡veis ordinais)
* One-Hot Encoding (variÃ¡veis nominais)
* NormalizaÃ§Ã£o (StandardScaler)
* Balanceamento (SMOTE)
* Feature Selection (Mutual Information)

5. **ARQUIVOS EXPORTADOS:**
* X_train_full.csv
*  X_test_full.csv
* X_train_balanced.csv
* X_train_selected.csv
* y_train.csv / y_test.csv / y_train_balanced.csv
* scaler.pkl
* selected_features.txt
* metadata.json

---

**PRÃ“XIMOS PASSOS:**

```
   â†’ Notebook 04: Modelagem Preditiva
   â†’ Treinar mÃºltiplos algoritmos
   â†’ Avaliar performance
   â†’ Selecionar melhor modelo
   â†’ Interpretar resultados
```


##  ğŸ‘€ 13. VisualizaÃ§Ã£o Final - Feature Importance

**Features criadas no Top 20: 10 (50%)**:

  ```
  â€¢ CompositeRiskScore
  â€¢ CompositeRiskScore_Normalized
  â€¢ IsLongTermContract
  â€¢ IsMonthlyContract
  â€¢ TenureYears
  â€¢ ChargesRatio
  â€¢ HighRiskPaymentContract
  â€¢ EstimatedCLV
  â€¢ IsNewCustomer
  â€¢ ChargesDifference
  ```

<img src="../src/notebooks/03_img10.png" width="900">
<img src="../src/notebooks/03_img11.png" width="900">


## ğŸ’¡ ConclusÃ£o

O que foi realizado:

##### 1. **CriaÃ§Ã£o de 29 novas features** baseadas em:
- Conhecimento de negÃ³cio
- Insights do EDA
- CombinaÃ§Ãµes de variÃ¡veis existentes

##### 2. **TransformaÃ§Ãµes aplicadas:**
- Encoding de categÃ³ricas (Label + One-Hot)
- NormalizaÃ§Ã£o de numÃ©ricas
- Balanceamento de classes (SMOTE)
- SeleÃ§Ã£o de features (Mutual Information)

##### 3. **Datasets preparados:**
- Completo (todas as features)
- Balanceado (SMOTE)
- Selecionado (top features)


## ğŸš€ Como Executar

### 1ï¸âƒ£ PrÃ©-requisitos

```bash
pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn
```

### 2ï¸âƒ£ Executar Notebook

```bash
cd notebooks
jupyter notebook 03_engenharia_feature.ipynb
```
### 3ï¸âƒ£ Executar Todas as CÃ©lulas

```Kernel â†’ Restart & Run All```

---
## â¡ï¸ PrÃ³ximos Passos

**Notebook 04 - Modelagem Preditiva:**

- âœ… Treinar mÃºltiplos algoritmos (RF, XGBoost, LightGBM)
- âœ… Avaliar performance (AUC-ROC, Precision, Recall)
- âœ… Tuning de hiperparÃ¢metros
- âœ… SeleÃ§Ã£o do melhor modelo
- âœ… AnÃ¡lise de feature importance
- âœ… Curvas de aprendizado

---

## ğŸ”„ Notas de VersÃ£o

| VersÃ£o | Data       | DescriÃ§Ã£o                                                           |
| ------ | ---------- | ------------------------------------------------------------------- |
| 1.0    | 09/02/2026 | Engeharia das features completa implementada                        |
| 1.1    | 11/02/2026 | DocumentaÃ§Ã£o ExportaÃ§Ã£o                                             |
| 1.2    | 12/02/2026 | AtualizaÃ§Ã£o no trecho do cÃ³digo em:11.2. Dados balanceados (SMOTE)  |
| 2.0    | 25/02/2026 | AtualizaÃ§Ã£o e revisÃ£o final do conteÃºdo                             |


## ğŸ‘¤ **Autor**
**Nome:** Ivan Ajala  
**FunÃ§Ã£o:** Data Scientist  
**Projeto:** Telco Customer Churn Prediction

![GitHub](https://img.shields.io/badge/GitHub-IvanAjala-181717?logo=github)
![LinkedIn](https://img.shields.io/badge/LinkedIn-ivan_ajala-0A66C2?logo=linkedin)
![Email](https://img.shields.io/badge/Email-ivan_ajala@hotmail.com-red)

**â­ Se este projeto foi Ãºtil, considere dar uma estrela no GitHub!**

  [![Estrelas](https://img.shields.io/github/stars/IvanAjala/ivan-ajala-ds-portfolio?style=social)](https://github.com/IvanAjala/ivan-ajala-ds-portfolio/stargazers)
  [![Forks](https://img.shields.io/github/forks/IvanAjala/ivan-ajala-ds-portfolio?style=social)](https://github.com/IvanAjala/ivan-ajala-ds-portfolio/network/members)
  [![LicenÃ§a](https://img.shields.io/badge/LicenÃ§a-MIT-green)](https://github.com/IvanAjala/ivan-ajala-ds-portfolio/blob/main/projects/01-telco-customer-churn-prediction/LICENSE)
  [![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
  [![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)

### ğŸ”— NavegaÃ§Ã£o RÃ¡pida

**â¬…ï¸ [Anterior](./README_02_analise_exploratoria.md)** | **[ğŸ” Voltar ao topo](#-visÃ£o-geral)** | **â¡ï¸ [PrÃ³ximo](./README_04_modelagem_preditiva.md)**

---
